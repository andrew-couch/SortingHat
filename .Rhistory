1/seq(1,10000,length = 100)
seq(1,0,length.out = 10000)
seq(1,0,length.out = 1000)
seq(.999999,.0000001,length.out = 1000)
seq(.99999,.0000001,length.out = 1000)
seq(.99999,.00001,length.out = 1000)
10^seq(-3,3, length = 100)
library(tidyverse)
library(caret)
library(doParallel)
alarm()
library(tidyverse)
install.packages("dplyr")
library(tidyverse)
install.packages(c("assertthat", "backports", "boot", "broom", "cairoDevice", "clipr", "cluster", "colorspace", "covr", "curl", "data.table", "dbplyr", "digest", "english", "evaluate", "forcats", "foreign", "ggplot2", "ggthemes", "glue", "gtable", "harrypotter", "haven", "highr", "hms", "htmlTable", "htmltools", "htmlwidgets", "httpuv", "httr", "KernSmooth", "knitr", "later", "lazyeval", "markdown", "MASS", "Matrix", "mgcv", "mgsub", "mime", "modelr", "nlme", "openssl", "pillar", "pkgbuild", "pkgconfig", "pROC", "progress", "promises", "purrr", "R6", "RcppParallel", "readxl", "recipes", "reprex", "rmarkdown", "rpart", "rstudioapi", "rvest", "RWeka", "RWekajars", "shiny", "slam", "stringi", "stringr", "survival", "sys", "tibble", "tidyr", "tinytex", "whisker", "xfun", "xml2", "zip"))
library(tidyverse)
library(caret)
install.packages("nnet")
library(caret)
irirs
iris
df <- iris
modelTest <- train(Species~., data = df, method = "knn")
modelTest <- train(Species~., data = df, method = "multinom")
modelTest
alarm()
alarm()
?alarm
browseURL('https://www.youtube.com/watch?v=QH2-TGUlwu4')
library(caret)
iris
iris
testModel <- train(Species~., data = iris, method = "glm")
testModel <- train(Species~., data = iris, method = "bayesglm")
testMo
testModel
setwd("E:/School/R Work")
library(tidyverse)
library(caret)
df <- readRDS("harrypotter.rds")
LogisticRegressionModel <- readRDS("LogisticRegressionModel.rds")
NaiveBayesModel <- readRDS("NaiveBayesModel.rds")
L1Model <- readRDS("L1Model.rds")
L2Model <- readRDS("L2Model.rds")
ElasticNetModel <- readRDS("ElasticNetModel.rds")
MARSModel <- readRDS("MARSModel.rds")
KnnModel <- readRDS("KnnModel.rds")
RandomForestModel <- readRDS("RandomForestModel.rds")
SVMModel <- readRDS("SupportVectorMachineModel.rds")
setwd("E:/School/R Work/SortingHat")
df <- readRDS("harrypotter.rds")
LogisticRegressionModel <- readRDS("LogisticRegressionModel.rds")
NaiveBayesModel <- readRDS("NaiveBayesModel.rds")
L1Model <- readRDS("L1Model.rds")
L2Model <- readRDS("L2Model.rds")
ElasticNetModel <- readRDS("ElasticNetModel.rds")
MARSModel <- readRDS("MARSModel.rds")
KnnModel <- readRDS("KnnModel.rds")
RandomForestModel <- readRDS("RandomForestModel.rds")
SVMModel <- readRDS("SupportVectorMachineModel.rds")
testData <- df
df$character <- NULL
df$TargetHouse <- as.factor(df$TargetHouse)
testData <- df
trainData <- upSample(df %>% select(-TargetHouse), df$TargetHouse)
df <- readRDS("harrypotter.rds")
df$character <- NULL
df$TargetHouse <- as.factor(df$TargetHouse)
testData <- df
trainData <- upSample(df %>% select(-TargetHouse), df$TargetHouse)
results <- cbind(predict(LogisticRegressionModel, trainData),
predict(NaiveBayesModel, trainData),
predict(L1Model, trainData),
predict(L2Model,trainData),
predict(ElasticNetModel, trainData),
predict(MARSModel, trainData),
predict(KnnModel, trainData),
predict(RandomForestModel, trainData),
predict(SVMModel, trainData), df$TargetHouse) %>%
as.data.frame()
results <- cbind(predict(LogisticRegressionModel, trainData),
predict(NaiveBayesModel, trainData),
predict(L1Model, trainData),
predict(L2Model,trainData),
predict(ElasticNetModel, trainData),
predict(MARSModel, trainData),
predict(KnnModel, trainData),
predict(RandomForestModel, trainData),
predict(SVMModel, trainData), trainData$Class) %>%
as.data.frame()
colnames(results) <- c("Logistic","NaiveBayes","L1","L2","ElasticNet","MARS","Knn","RandomForest","SVM", "Actual")
results
results$Actual
results$Actual %>%
count(Acutal)
ensembleTrain <- cbind(predict(LogisticRegressionModel, trainData),
predict(NaiveBayesModel, trainData),
predict(L1Model, trainData),
predict(L2Model,trainData),
predict(ElasticNetModel, trainData),
predict(MARSModel, trainData),
predict(KnnModel, trainData),
predict(RandomForestModel, trainData),
predict(SVMModel, trainData), trainData$Class) %>%
as.data.frame()
colnames(ensembleTrain) <- c("Logistic","NaiveBayes","L1","L2","ElasticNet","MARS","Knn","RandomForest","SVM", "Actual")
ensembleTrain$Actual <- as.factor(ensembleTrain$Actual)
ensembleModel <- train(Actual~., data = ensembleTrain, method = "xgbLinear")
library(tidyverse)
library(caret)
library(doParallel)
library(beepr)
beep(7)
beep(6)
beep(5)
beep(4)
beep(3)
df <- readRDS("harrypotter.rds")
df$character <- NULL
df$TargetHouse <- as.factor(df$TargetHouse)
testData <- df
trainData <- upSample(df %>% select(-TargetHouse), df$TargetHouse)
LogisticRegressionModel <- readRDS("LogisticRegressionModel.rds")
NaiveBayesModel <- readRDS("NaiveBayesModel.rds")
L1Model <- readRDS("L1Model.rds")
L2Model <- readRDS("L2Model.rds")
ElasticNetModel <- readRDS("ElasticNetModel.rds")
MARSModel <- readRDS("MARSModel.rds")
KnnModel <- readRDS("KnnModel.rds")
RandomForestModel <- readRDS("RandomForestModel.rds")
SVMModel <- readRDS("SupportVectorMachineModel.rds")
ensembleTrain <- cbind(predict(LogisticRegressionModel, trainData),
predict(NaiveBayesModel, trainData),
predict(L1Model, trainData),
predict(L2Model,trainData),
predict(ElasticNetModel, trainData),
predict(MARSModel, trainData),
predict(KnnModel, trainData),
predict(RandomForestModel, trainData),
predict(SVMModel, trainData), trainData$Class) %>%
as.data.frame()
colnames(ensembleTrain) <- c("Logistic","NaiveBayes","L1","L2","ElasticNet","MARS","Knn","RandomForest","SVM", "Actual")
ensembleTest <- cbind(predict(LogisticRegressionModel, testData),
predict(NaiveBayesModel, testData),
predict(L1Model, testData),
predict(L2Model,testData),
predict(ElasticNetModel, testData),
predict(MARSModel, testData),
predict(KnnModel, testData),
predict(RandomForestModel, testData),
predict(SVMModel, testData), testData$TargetHouse) %>%
as.data.frame()
colnames(ensembleTest) <- c("Logistic","NaiveBayes","L1","L2","ElasticNet","MARS","Knn","RandomForest","SVM", "Actual")
View(ensembleTest)
ensembleTrain$Actual <- as.factor(ensembleTrain$Actual)
ensembleModel <- train(Actual~., data = ensembleTrain, method = "xgbLinear")
beep(3)
ensembleModel
predict(ensembleModel, ensembleTest)
predict(ensembleModel, ensembleTest) %>% cbind(ensembleTest$Actual)
predict(ensembleModel, ensembleTest) %>% cbind(ensembleTest$Actual) %>% as.data.frame()
predict(ensembleModel, ensembleTest) %>%
cbind(ensembleTest$Actual) %>%
as.data.frame() %>%
rename(., "predicted" = ., "actual" = V2)
predict(ensembleModel, ensembleTest) %>%
cbind(ensembleTest$Actual) %>%
as.data.frame() %>%
rename(., "predicted" = ., "actual" = V2) %>%
mutate(results = if_else(predicted == actual, "correct","wrong"))
source('~/.active-rstudio-document', echo=TRUE)
predict(ensembleModel, ensembleTest) %>%
cbind(ensembleTest$Actual) %>%
as.data.frame() %>%
rename(., "predicted" = ., "actual" = V2) %>%
mutate(results = if_else(predicted == actual, "correct","wrong")) %>%
filter(results == "correct")
predict(ensembleModel, ensembleTest) %>%
cbind(ensembleTest$Actual) %>%
as.data.frame() %>%
rename(., "predicted" = ., "actual" = V2) %>%
mutate(results = if_else(predicted == actual, "correct","wrong")) %>%
filter(results == "correct") %>%
nrow() / nrow(ensembleTrain)
predict(ensembleModel, ensembleTest) %>%
cbind(ensembleTest$Actual) %>%
as.data.frame() %>%
rename(., "predicted" = ., "actual" = V2) %>%
mutate(results = if_else(predicted == actual, "correct","wrong")) %>%
filter(results == "correct") %>%
nrow()
predict(ensembleModel, ensembleTest) %>%
cbind(ensembleTest$Actual) %>%
as.data.frame() %>%
rename(., "predicted" = ., "actual" = V2) %>%
mutate(results = if_else(predicted == actual, "correct","wrong")) %>%
filter(results == "correct") %>%
nrow() / nrow(ensembleTest)
saveRDS(ensembleModel, "EnsembleModel.rds")
install.packages("rtweet")
library(tidyverse)
library(rtweet)
library(tidytext)
library(sentimentr)
library(ggradar)
library(doParallel)
cl <- makePSOCKcluster(7)
registerDoParallel(cl)
StartTime <- Sys.time()
userName <- "TheAtlantic"
bow <- read.csv("bowlist.csv", header = TRUE,stringsAsFactors = FALSE)
bigram <- read.csv("bigramlist.csv", header = TRUE,stringsAsFactors = FALSE)
trigram <- read.csv("trigramlist.csv", header = TRUE,stringsAsFactors = FALSE)
token <- readRDS("twitter_token.rds")
myTweets <- get_timeline(userName, n = 3200)
tweetData <- myTweets %>%
filter(is_retweet == FALSE) %>%
select(text) %>%
mutate(userName = userName)
tweetData$text <- str_trim(gsub('http\\S+\\s*',"", tweetData$text))
tweetData$text <- gsub("(^|[^@\\w])@(\\w{1,15})\\b", "", tweetData$text)
tweetData <- tweetData %>%
filter(!text %in% c(" ", "", "   "))
bowFeatures <- tweetData %>%
unnest_tokens(word, "text") %>%
right_join(bow, by = c("word" = "bow")) %>%
count(word, word) %>%
mutate(n = n-1) %>%
spread(word, n)
bigramFeatures <- tweetData %>%
unnest_tokens(bigram, "text", token = "ngrams", n = 2) %>%
right_join(bigram, by = c("bigram" = "bigram")) %>%
count(bigram, bigram) %>%
mutate(n = n-1) %>%
spread(bigram, n)
trigramFeatures <- tweetData %>%
unnest_tokens(trigram, "text", token = "ngrams", n = 3) %>%
right_join(trigram, by = c("trigram" = "trigram")) %>%
count(trigram, trigram) %>%
mutate(n = n-1) %>%
spread(trigram, n)
sentences <- tweetData %>% select(text) %>% get_sentences()
sentiments <- cbind(
sentences %>%
sentiment((lexicon::hash_sentiment_huliu)) %>%
select(sentiment) %>%
rename("huliu" = sentiment),
sentences %>%
sentiment(lexicon::hash_sentiment_jockers_rinker) %>%
select(sentiment) %>%
rename("jockers_rinker" = sentiment),
sentences %>%
sentiment(lexicon::hash_sentiment_nrc) %>%
select(sentiment) %>%
rename("nrc" = sentiment),
sentences %>%
sentiment(lexicon::hash_sentiment_senticnet) %>%
select(sentiment) %>%
rename("senticnet" = sentiment),
sentences %>%
sentiment(lexicon::hash_sentiment_sentiword) %>%
select(sentiment) %>%
rename("sentiword" = sentiment),
sentences %>%
sentiment(lexicon::hash_sentiment_slangsd) %>%
select(sentiment) %>%
rename("slangsd" = sentiment),
sentences %>%
sentiment(lexicon::hash_sentiment_socal_google) %>%
select(sentiment) %>%
rename("socal_google" = sentiment))
sentiments <-  sentiments %>%
gather(key = "sentiment", value = "score") %>%
group_by(sentiment) %>%
summarise(score = mean(score)) %>%
spread(key = sentiment, value = score)
emotions <- lexicon::nrc_emotions
emotionFeatures <- sentences %>%
unnest_tokens(word, "text") %>%
filter(word %in% emotions$term) %>%
left_join(emotions, by = c("word" = "term")) %>%
select(-word,-element_id, -sentence_id) %>%
summarise_each(funs(sum)) %>%
gather(key = "sentiment", value = "score") %>%
mutate(score = score / sentences %>% unnest_tokens(word, "text") %>% nrow()) %>%
spread(sentiment, score) %>%
rename("anger.emotion" = anger,
"anticipation.emotion" = anticipation,
"digust.emotion" = disgust,
"fear.emotion" = fear,
"joy.emotion" = joy,
"sadness.emotion" = sadness,
"surprise.emotion" = surprise,
"trust.emotion" = trust)
df <- cbind(bowFeatures, bigramFeatures, trigramFeatures, sentiments, emotionFeatures)
LogisticRegressionModel <- readRDS("LogisticRegressionModel.rds")
NaiveBayesModel <- readRDS("NaiveBayesModel.rds")
L1Model <- readRDS("L1Model.rds")
L2Model <- readRDS("L2Model.rds")
ElasticNetModel <- readRDS("ElasticNetModel.rds")
MARSModel <- readRDS("MARSModel.rds")
KnnModel <- readRDS("KnnModel.rds")
RandomForestModel <- readRDS("RandomForestModel.rds")
SVMModel <- readRDS("SupportVectorMachineModel.rds")
EnsembleModel <- readRDS("EnsembleModel.rds")
df
ensembleData <- cbind(predict(LogisticRegressionModel, testData),
predict(NaiveBayesModel, testData),
predict(L1Model, testData),
predict(L2Model,testData),
predict(ElasticNetModel, testData),
predict(MARSModel, testData),
predict(KnnModel, testData),
predict(RandomForestModel, testData),
predict(SVMModel, testData))
ensembleData <- cbind(predict(LogisticRegressionModel, df),
predict(NaiveBayesModel, df),
predict(L1Model, df),
predict(L2Model,df),
predict(ElasticNetModel, df),
predict(MARSModel, df),
predict(KnnModel, testData),
predict(RandomForestModel, df),
predict(SVMModel, df))
ensembleData <- cbind(predict(LogisticRegressionModel, df),
predict(NaiveBayesModel, df),
predict(L1Model, df),
predict(L2Model,df),
predict(ElasticNetModel, df),
predict(MARSModel, df),
predict(KnnModel, df),
predict(RandomForestModel, df),
predict(SVMModel, df))
ensembleData
ensembleData <- cbind(predict(LogisticRegressionModel, df),
predict(NaiveBayesModel, df),
predict(L1Model, df),
predict(L2Model,df),
predict(ElasticNetModel, df),
predict(MARSModel, df),
predict(KnnModel, df),
predict(RandomForestModel, df),
predict(SVMModel, df)) %>% as.data.frame()
colnames(ensembleData) <- c("Logistic","NaiveBayes","L1","L2","ElasticNet","MARS","Knn","RandomForest","SVM")
ensembleData
HousePrediction <- predict(EnsembleModel, ensembleData, type = "prob")
HousePrediction
predict(EnsembleModel, ensembleData)
predict(LogisticRegressionModel, df)
colnames(HousePrediction) <- c("Gryffindor", "Hufflepuff", "Ravenclaw", "Slytherin")
stopCluster(cl)
HousePrediction
HousePrediction %>% mutate(Name = userName)
HousePrediction %>%
mutate(Name = userName) %>%
as_tibble(rownames = Name)
HousePrediction %>%
mutate(Name = userName) %>%
as_tibble(rownames = "Name")
HousePrediction %>%
mutate(Name = userName) %>%
as_tibble(rownames = "Name")
HousePrediction %>% mutate(Name = userName)
HousePrediction %>% mutate(Name = userName) %>%
column_to_rownames("Name")
HousePrediction %>% mutate(Name = userName) %>%
column_to_rownames("Name") %>%
ggradar()
HousePrediction %>% mutate(Name = userName) %>%
column_to_rownames("Name")
HousePrediction %>% mutate(Name = userName) %>%
column_to_rownames("Name") %>%
ungroup() %>%
as_tibble(rownames = "Name")
HousePrediction %>% mutate(Name = userName) %>%
column_to_rownames("Name") %>%
ungroup() %>%
as_tibble(rownames = "Name") %>%
ggradar()
HousePrediction
HousePrediction %>% mutate_all(round(2))
HousePrediction %>% mutate_all(scales::percent())
HousePrediction %>% mutate_all(scales::percent(x))
HousePrediction %>% mutate_all(scales::percent(.))
HousePrediction
library(tidyverse)
library(rtweet)
library(tidytext)
library(sentimentr)
library(ggradar)
library(doParallel)
cl <- makePSOCKcluster(7)
registerDoParallel(cl)
StartTime <- Sys.time()
userName <- "_AndrewCouch"
bow <- read.csv("bowlist.csv", header = TRUE,stringsAsFactors = FALSE)
bigram <- read.csv("bigramlist.csv", header = TRUE,stringsAsFactors = FALSE)
trigram <- read.csv("trigramlist.csv", header = TRUE,stringsAsFactors = FALSE)
token <- readRDS("twitter_token.rds")
myTweets <- get_timeline(userName, n = 3200)
tweetData <- myTweets %>%
filter(is_retweet == FALSE) %>%
select(text) %>%
mutate(userName = userName)
tweetData$text <- str_trim(gsub('http\\S+\\s*',"", tweetData$text))
tweetData$text <- gsub("(^|[^@\\w])@(\\w{1,15})\\b", "", tweetData$text)
tweetData <- tweetData %>%
filter(!text %in% c(" ", "", "   "))
bowFeatures <- tweetData %>%
unnest_tokens(word, "text") %>%
right_join(bow, by = c("word" = "bow")) %>%
count(word, word) %>%
mutate(n = n-1) %>%
spread(word, n)
bigramFeatures <- tweetData %>%
unnest_tokens(bigram, "text", token = "ngrams", n = 2) %>%
right_join(bigram, by = c("bigram" = "bigram")) %>%
count(bigram, bigram) %>%
mutate(n = n-1) %>%
spread(bigram, n)
trigramFeatures <- tweetData %>%
unnest_tokens(trigram, "text", token = "ngrams", n = 3) %>%
right_join(trigram, by = c("trigram" = "trigram")) %>%
count(trigram, trigram) %>%
mutate(n = n-1) %>%
spread(trigram, n)
sentences <- tweetData %>% select(text) %>% get_sentences()
sentiments <- cbind(
sentences %>%
sentiment((lexicon::hash_sentiment_huliu)) %>%
select(sentiment) %>%
rename("huliu" = sentiment),
sentences %>%
sentiment(lexicon::hash_sentiment_jockers_rinker) %>%
select(sentiment) %>%
rename("jockers_rinker" = sentiment),
sentences %>%
sentiment(lexicon::hash_sentiment_nrc) %>%
select(sentiment) %>%
rename("nrc" = sentiment),
sentences %>%
sentiment(lexicon::hash_sentiment_senticnet) %>%
select(sentiment) %>%
rename("senticnet" = sentiment),
sentences %>%
sentiment(lexicon::hash_sentiment_sentiword) %>%
select(sentiment) %>%
rename("sentiword" = sentiment),
sentences %>%
sentiment(lexicon::hash_sentiment_slangsd) %>%
select(sentiment) %>%
rename("slangsd" = sentiment),
sentences %>%
sentiment(lexicon::hash_sentiment_socal_google) %>%
select(sentiment) %>%
rename("socal_google" = sentiment))
sentiments <-  sentiments %>%
gather(key = "sentiment", value = "score") %>%
group_by(sentiment) %>%
summarise(score = mean(score)) %>%
spread(key = sentiment, value = score)
emotions <- lexicon::nrc_emotions
emotionFeatures <- sentences %>%
unnest_tokens(word, "text") %>%
filter(word %in% emotions$term) %>%
left_join(emotions, by = c("word" = "term")) %>%
select(-word,-element_id, -sentence_id) %>%
summarise_each(funs(sum)) %>%
gather(key = "sentiment", value = "score") %>%
mutate(score = score / sentences %>% unnest_tokens(word, "text") %>% nrow()) %>%
spread(sentiment, score) %>%
rename("anger.emotion" = anger,
"anticipation.emotion" = anticipation,
"digust.emotion" = disgust,
"fear.emotion" = fear,
"joy.emotion" = joy,
"sadness.emotion" = sadness,
"surprise.emotion" = surprise,
"trust.emotion" = trust)
df <- cbind(bowFeatures, bigramFeatures, trigramFeatures, sentiments, emotionFeatures)
LogisticRegressionModel <- readRDS("LogisticRegressionModel.rds")
NaiveBayesModel <- readRDS("NaiveBayesModel.rds")
L1Model <- readRDS("L1Model.rds")
L2Model <- readRDS("L2Model.rds")
ElasticNetModel <- readRDS("ElasticNetModel.rds")
MARSModel <- readRDS("MARSModel.rds")
KnnModel <- readRDS("KnnModel.rds")
RandomForestModel <- readRDS("RandomForestModel.rds")
SVMModel <- readRDS("SupportVectorMachineModel.rds")
EnsembleModel <- readRDS("EnsembleModel.rds")
ensembleData <- cbind(predict(LogisticRegressionModel, df),
predict(NaiveBayesModel, df),
predict(L1Model, df),
predict(L2Model,df),
predict(ElasticNetModel, df),
predict(MARSModel, df),
predict(KnnModel, df),
predict(RandomForestModel, df),
predict(SVMModel, df)) %>% as.data.frame()
colnames(ensembleData) <- c("Logistic","NaiveBayes","L1","L2","ElasticNet","MARS","Knn","RandomForest","SVM")
predict(LogisticRegressionModel, df)
HousePrediction <- predict(EnsembleModel, ensembleData, type = "prob")
colnames(HousePrediction) <- c("Gryffindor", "Hufflepuff", "Ravenclaw", "Slytherin")
stopCluster(cl)
EndTime <- Sys.time()
StartTime - EndTime
HousePrediction %>% mutate(Name = userName) %>%
column_to_rownames("Name") %>%
ungroup() %>%
as_tibble(rownames = "Name") %>%
ggradar()
HousePrediction
