library(tidytext)
library(sentimentr)
df <- read.csv("harrypotter.csv")
df$text <- as.character(df$text)
nameList <- read.csv("namelist.csv")
#This section creates ngram features
#The features will be grouped by character
#Characters are different for each medium there's a movie_harry and book_harry
#May group characters by medium and book which would be Chamber_Of_Secrets_Movie_Harry
#Creates word list for bag of words feature
wordList <- df %>%
select(text) %>%
unnest_tokens(word, "text") %>%
anti_join(stop_words) %>%
filter(!str_detect(word, pattern = "[[:digit:]]"),
!str_detect(word, pattern = "[[:punct:]]"),
!str_detect(word, pattern = "(.)\\1{2,}"),
!str_detect(word, pattern = "\\b(.)\\b")) %>%
count(word, sort = TRUE) %>%
filter(n > 10) %>%
pull(word)
#generates bag of words features
bowFeatures <- df %>%
unnest_tokens(word, "text") %>%
anti_join(stop_words) %>%
filter(word %in%  wordList) %>%
count(character, word) %>%
spread(word, n) %>%
map_df(replace_na, 0)
#creates bigram list for bigram features
bigramList <- df %>%
select(text) %>%
unnest_tokens(bigram, "text", token = "ngrams", n = 2) %>%
separate(bigram, c("word1", "word2"), sep = " ") %>%
filter(!word1 %in% stop_words$word,
!word2 %in% stop_words$word,
!str_detect(word1, pattern = "[[:digit:]]"),
!str_detect(word2, pattern = "[[:digit:]]"),
!str_detect(word1, pattern = "[[:punct:]]"),
!str_detect(word2, pattern = "[[:punct:]]"),
!str_detect(word1, pattern = "(.)\\1{2,}"),
!str_detect(word2, pattern = "(.)\\1{2,}"),
!str_detect(word1, pattern = "\\b(.)\\b"),
!str_detect(word1, pattern = "\\b(.)\\b")) %>%
unite("bigram", c(word1, word2), sep = " ") %>%
count(bigram) %>%
filter(n > 2) %>%
pull(bigram)
#creates bigram features
bigramFeatures <- df %>%
unnest_tokens(bigram, "text", token = "ngrams", n = 2) %>%
filter(bigram %in% bigramList) %>%
count(character, bigram) %>%
spread(bigram, n) %>%
map_df(replace_na, 0)
#creates trigram list for trigram features
trigramList <- df %>%
unnest_tokens(trigram, "text", token = "ngrams", n = 3) %>%
separate(trigram, c("word1","word2","word3"), sep = " ") %>%
filter(!word1 %in% stop_words$word,
!str_detect(word1, pattern = "[[:digit:]]"),
!str_detect(word1, pattern = "[[:punct:]]"),
!str_detect(word1, pattern = "(.)\\1{2,}"),
!str_detect(word1, pattern = "\\b(.)\\b"),
!word2 %in% stop_words$word,
!str_detect(word2, pattern = "[[:digit:]]"),
!str_detect(word2, pattern = "[[:punct:]]"),
!str_detect(word2, pattern = "(.)\\1{2,}"),
!str_detect(word2, pattern = "\\b(.)\\b"),
!word3 %in% stop_words$word,
!str_detect(word3, pattern = "[[:digit:]]"),
!str_detect(word3, pattern = "[[:punct:]]"),
!str_detect(word3, pattern = "(.)\\1{2,}"),
!str_detect(word3, pattern = "\\b(.)\\b")) %>%
unite("trigram", c(word1, word2, word3), sep = " ") %>%
count(trigram) %>%
filter(n > 2) %>%
pull(trigram)
#creates trigram features
trigramFeatures <- df %>%
unnest_tokens(trigram, "text", token = "ngrams", n = 3) %>%
filter(trigram %in% trigramList) %>%
count(character, trigram) %>%
spread(trigram, n) %>%
map_df(replace_na,0)
#This section creates lexicon sentiment analysis features
#data will need to be processed on a sentence level using sentimentR
#This section will add an tf-idf feature (term frequency and inverse document frequency)
#Where document will be each movie or book
#Weights words and may help separating the houses
tf_idfWOrdList <- df %>%
filter(house != "No Entry") %>%
get_sentences() %>%
unnest_tokens(word, "text") %>%
filter(!word %in% nameList$value,
!str_detect(word, pattern = "[[:digit:]]"),
!str_detect(word, pattern = "[[:punct:]]"),
!str_detect(word, pattern = "(.)\\1{2,}"),
!str_detect(word, pattern = "\\b(.)\\b"),
!word %in% stop_words$word) %>%
count(house, word, sort = TRUE) %>%
bind_tf_idf(word, house, n) %>%
filter(tf_idf > median(tf_idf)) %>%
pull(word)
library(rattle)
rattle()
library(rattle)
rattle()
df <- read.csv("UI_ISU.csv")
df$Iowa[20] <- 18
df$ISU[20] <- 17
df$margin <- abs(df$Iowa - df$ISU)
df$IowaWin <- df$Iowa > df$ISU
df$IowaWin <- as.factor(df$IowaWin)
df$IowaWin <- as.integer(df$IowaWin)
library(tidytext)
library(tidyverse)
df <- "I like dogs. I like cats."
library(tidytext)
library(tidyverse)
df <- "I like dogs. I like cats."
df %>% sentences
sentences
df %>% unnest_tokens(sentence)
df %>% unnest_tokens(sentence, token = "sentences")
unnest_tokens(sentence, "I like dogs. I like cats.",token = "sentences")
unnest_tokens(sentence, "I like dogs. I like cats.",token = "sentences")
unnest_tokens("I like dogs. I like cats.",token = "sentences")
df %>% as.data.frame()
df <- df %>% as.data.frame()
unnest_tokens(sentence, df,token = "sentences")
unnest_tokens(sentence, df ,token = "sentences")
unnest_tokens( df ,token = "sentences")
df %>% unnest_tokens(sentence, df$., token = "sentences")
df <- data.frame("text" = "I like cats. I like dogs. I hate humans.")
View(df)
df %>% unnest_tokens(sentence, "text", token = "sentences")
df %>% unnest_tokens(sentence, "text", token = "sentences") %>%
unnest_tokens(word, "sentence", token = "words")
df %>% unnest_tokens(sentence, "text", token = "sentences") %>%
unnest_tokens(word, "sentence", token = "words") %>%
count(word)
df %>% unnest_tokens(sentence, "text", token = "sentences") %>%
unnest_tokens(word, "sentence", token = "words") %>%
count(word)
df %>% unnest_tokens(sentence, "text", token = "sentences")
df %>% unnest_tokens(sentence, "text", token = "sentences") %>% view()
df <- data.frame("text" = c("I like dogs.","I like cats.","I hate turtles.","I like turtles."))
View(df)
df %>% unnest_tokens(sentence, "text", token = "sentences")
df %>% unnest_tokens(sentence, "text", token = "sentences") %>% view()
df %>% unnest_tokens(word, "text", token = "words")
df %>% unnest_tokens(word, "text", token = "word")
df %>% unnest_tokens(word, "text", token = "words")
df %>% unnest_tokens(word, "text")
df %>% unnest_tokens(word, "text")
df
df %>% unnest_tokens(word, "text")
df %>% unnest_tokens(word, text)
str(df)
df %>% as.character()
df$text <- df$text %>% as.character()
df %>% unnest_tokens(word, text)
df %>% unnest_tokens(word, text) %>% view()
df <- data.frame("text" = c("I like dogs.","I like cats.","I hate turtles.","I like turtles."), line = 1:4)
df$text <- df$text %>% as.character()
df %>% unnest_tokens(word, text) %>% view()
df %>%
unnest_tokens(word, text) %>%
count(line, word) %>%
bind_tf_idf(word,line,n)
df %>%
unnest_tokens(word, text) %>%
count(line, word) %>%
bind_tf_idf(word,line,n) %>%
filter(tf_idf != 0)
df %>%
unnest_tokens(word, text) %>%
count(line, word) %>%
bind_tf_idf(word, line, n) %>%
filter(tf_idf != 0)
df %>%
unnest_tokens(word, text) %>%
count(line, word) %>%
bind_tf_idf(word, line, n) %>%
filter(tf_idf != 0) %>%
arrange(line)
df %>%
unnest_tokens(word, text) %>%
count(line,word) %>%
group_by(line) %>%
top_n(n,n=2)
df %>%
unnest_tokens(word, text) %>%
count(line,word) %>%
arrange(line)
df %>%
unnest_tokens(word, text) %>%
count(line, word) %>%
bind_tf_idf(word, line, n) %>%
filter(tf_idf != 0) %>%
arrange(line)
df %>%
unnest_tokens(word, text) %>%
count(line,word) %>%
arrange(line)
.333/1.39
df <- data.frame("text" = c("I like dogs.",
"I like cats.",
"I like turtles.",
"I like penguins."), line = 1:4)
df$text <- df$text %>% as.character()
df %>%
unnest_tokens(word, text) %>%
count(line, word) %>%
bind_tf_idf(line, word, n)
df %>%
unnest_tokens(word, text) %>%
count(line, word) %>%
bind_tf_idf(word, line, n)
df %>%
unnest_tokens(word, text) %>%
count(line, word) %>%
bind_tf_idf(word, line, n) %>%
filter(tf_idf != 0)
df %>%
unnest_tokens(word, text) %>%
count(line, word) %>%
bind_tf_idf(word, line, n) %>%
filter(tf_idf != 0)
df %>%
unnest_tokens(word,text) %>%
count(line,word)
df %>%
unnest_tokens(word, text) %>%
count(line, word) %>%
bind_tf_idf(word, line, n) %>%
filter(tf_idf != 0)
df <- data.frame("text" = c("I like dogs.",
"I like cats.",
"I like turtles.",
"I like penguins.",
"I hate dogs",
"I hate cats",
"I hate turtles",
"I hate penguins"), line = 1:8)
df$text <- df$text %>% as.character()
df %>%
unnest_tokens(word, text) %>%
count(line, word) %>%
bind_tf_idf(word, line, n) %>%
filter(tf_idf != 0)
df %>%
unnest_tokens(word, text) %>%
count(line, word) %>%
bind_tf_idf(word, line, n) %>%
filter(tf_idf != 0) %>%
group_by(line) %>%
filter(tf_idf = max(tf_idf))
df %>%
unnest_tokens(word, text) %>%
count(line, word) %>%
bind_tf_idf(word, line, n) %>%
filter(tf_idf != 0) %>%
group_by(line) %>%
filter(tf_idf == max(tf_idf))
df %>%
unnest_tokens(word, text) %>%
count(line, word) %>%
bind_tf_idf(word, line, n) %>%
filter(tf_idf != 0) %>%
group_by(line)
df %>%
unnest_tokens(word, text) %>%
count(line, word) %>%
bind_tf_idf(word, line, n) %>%
filter(tf_idf != 0) %>%
group_by(line) %>%
arrange(line, tf_idf)
df %>%
unnest_tokens(word, text) %>%
count(line, word) %>%
bind_tf_idf(word, line, n) %>%
filter(tf_idf != 0) %>%
group_by(line) %>%
arrange(line, -tf_idf)
df %>%
unnest_tokens(word, text) %>%
count(line, word) %>%
bind_tf_idf(word, line, n) %>%
filter(tf_idf != 0) %>%
group_by(line) %>%
arrange(word)
df %>%
unnest_tokens(word, text) %>%
count(line, word) %>%
bind_tf_idf(word, line, n) %>%
filter(tf_idf != 0) %>%
group_by(line) %>%
arrange(tf_idf)
df %>%
unnest_tokens(word, text) %>%
count(line, word) %>%
bind_tf_idf(word, line, n) %>%
group_by(line) %>%
arrange(tf_idf)
df %>%
unnest_tokens(word, text) %>%
count(line, word) %>%
bind_tf_idf(word, line, n) %>%
group_by(line) %>%
arrange(-tf_idf)
df %>%
unnest_tokens(word, text) %>%
count(line, word) %>%
bind_tf_idf(word, line, n) %>%
group_by(line)
df <- data.frame("character" = c("John","John","John","John","Mary","Mary","Mary","Mary"),
"text" = c("I like dogs.",
"I like cats.",
"I like turtles.",
"I like penguins.",
"I hate dogs",
"I hate cats",
"I hate turtles",
"I hate penguins"), line = 1:8)
df$text <- df$text %>% as.character()
df %>%
unnest_tokens(word, text) %>%
count(line, word) %>%
bind_tf_idf(word, line, n) %>%
group_by(line)
df %>%
unnest_tokens(word, text) %>%
count(character, word) %>%
bind_tf_idf(word, character, n) %>%
group_by(line)
df %>%
unnest_tokens(word, text) %>%
count(character, word) %>%
bind_tf_idf(word, character, n) %>%
group_by(character)
df %>%
unnest_tokens(word, text) %>%
count(character, word) %>%
bind_tf_idf(word, character, n) %>%
group_by(character) %>%
top_n(tf_idf, n = 1)
df %>% unnest_tokens(word,text) %>%
count(character, word)
df %>% unnest_tokens(word,text) %>%
count(character, word) %>%
top_n(n, n =1)
df %>% unnest_tokens(word,text) %>%
count(character, word) %>%
group_by(character) %>%
top_n(n, n =1)
(tf_idf, n = 1)
df %>%
unnest_tokens(word, text) %>%
count(character, word) %>%
bind_tf_idf(word, character, n) %>%
group_by(character) %>%
top_n(tf_idf, n = 1)
df %>% unnest_tokens(word,text) %>%
count(character, word) %>%
group_by(character) %>%
top_n(n, n =1)
library(rattle)
rattle()
library(rattle)
rattle()
library(caret)
library(tidyverse)
iris
model <- train(Species~.,
data = iris,
method = "rf",
trCOntrol = trainControl(method = "boot",
classProbs = TRUE,
summaryFunction = multiClassSummary))
model
multiClassSummary(model)
multiClassSummary(model$pred)
multiClassSummary(model$pred, model$results)
?multiClassSummary
model$pred
model$finalModel$predicted
model$finalModel$y
model$finalModel$obsLevels
multiClassSummary(iris,model$finalModel$obsLevels, model)
multiClassSummary(iris,model$finalModel$obsLevels, model)
model$finalModel
model$finalModel$confusion
confusionMatrix(model)
model
model <- train(Species~.,
data = iris,
method = "rf",
trCOntrol = trainControl(method = "boot",
classProbs = TRUE,
summaryFunction = multiClassSummary),
metric = "recall")
extractProb(model)
extractProb(model$finalModel)
predict(model, iris, type = "prob")
predict(model, iris, type = "prob") %>% cbind(iris$Species)
library(rattle)
rattle()
library(rattle)
rattle()
mtcars
df <- mtcars
df$efficient <- ifelse(df$mpg <20, 0,1)
df$efficient2 <- as.numeric(df$mpg < 20)
df$efficient
df$efficient2
df$efficient2 <- as.numeric(df$mpg >= 20)
df$efficient2
df$mpg
View(df)
df <- mtcars
df$efficient <- ifelse(df$mpg <20, 0,1)
df$efficient2 <- as.numeric(df$mpg >= 20)
str(df)
#Andrew Couch
rm(list = ls())
#1
raw_df <- read.csv("scary_movies.txt")
movie_df <- read.csv("scary_movies.txt", sep = "\t", stringsAsFactors = FALSE,
na.strings = c("", " ", "-"),
colClasses = c("integer","character","integer","integer","factor","character","numeric","numeric","integer","integer","character","factor","factor"))
movie_df$ReleaseDate <- as.Date(movie_df$ReleaseDate, "%B%d,%Y")
#2
levels(movie_df$Language)
levels(movie_df$Genre1)
movie_df[which(movie_df$Genre1 == "Acion"),"Genre1"] <- "Action"
levels(movie_df$Genre1)[which(levels(movie_df$Genre1) == "Acion")] <- "Action"
movie_df[which(movie_df$Genre1 == "Horrror"),"Genre1"] <- "Horror"
levels(movie_df$Genre1)[which(levels(movie_df$Genre1) == "Horrror")] <- "Horror"
levels(movie_df$Genre1)
unique(movie_df$Genre1)
#3
movie_df$Profit <- as.integer(movie_df$Revenue - movie_df$Budget)
movie_df$ReleaseYear <- format(movie_df$ReleaseDate, "%Y")
movie_df$Decade <- as.factor(paste(substr(movie_df$ReleaseYear,1,3),"0s",sep =""))
#4
movie_df$PopularityNorm <- 10*(movie_df$Popularity - min(movie_df$Popularity)) / (max(movie_df$Popularity) - min(movie_df$Popularity))
#5
missing_columns <- colSums(is.na(movie_df))
movie_df$BudgetMedian <- movie_df$Budget
movie_df$BudgetMedian[which(is.na(movie_df$BudgetMedian))] <- median(movie_df$Budget, na.rm = TRUE)
DecadeTable <- aggregate(movie_df$Budget, by  = list(movie_df$Decade), FUN = mean, na.rm = TRUE)
movie_df$BudgetSimilar <- movie_df$Budget
movie_df$BudgetSimilar[which(is.na(movie_df$BudgetSimilar))] <- DecadeTable[match(movie_df[which(is.na(movie_df$BudgetSimilar)),"Decade"], DecadeTable$Group.1),"x"]
library(tidyverse)
library(tidytext)
df <- read.csv("DemDebates.csv", colClasses = c("factor","factor","character"))
df <- df %>%
filter(!character %in% c("(Unknown)", "Announcer","Bash","Bridgewater","Burnett","Cooper","Davis","Diaz-Balart","Guthrie","Holt","Jose Diaz-Balart","Lacey","Lemon","Lester Holt", "Maddow","Muir","Protesters","Protestor","Ramos","Savannah Guthrie","Stephanopoulos","Tapper","Todd","Unknown"))
options(scipen = 999)
df %>%
unnest_tokens(trigram, "text", token = "ngrams", n = 3) %>%
count(character, trigram) %>%
bind_tf_idf(trigram, character,n) %>%
group_by(character) %>%
top_n(tf_idf, n = 5) %>%
mutate(rank = rank(tf_idf, ties.method = "random")) %>%
arrange(character, rank) %>%
filter(rank <=5) %>%
ggplot(aes(x = reorder_within(trigram, tf_idf, character),
y = tf_idf,
color = character,
fill = character)) +
geom_col() +
scale_x_reordered() +
facet_wrap(~character, scales = "free") +
coord_flip() +
theme(legend.position = "None")
df %>%
unnest_tokens(trigram, "text", token = "ngrams", n = 3) %>%
count(character, trigram) %>%
bind_tf_idf(trigram, character,n) %>%
group_by(character) %>%
top_n(tf_idf, n = 5) %>%
mutate(rank = rank(tf_idf, ties.method = "random")) %>%
arrange(character, rank) %>%
filter(rank <=5) %>%
ggplot(aes(x = reorder_within(trigram, tf_idf, character),
y = tf_idf,
color = character,
fill = character)) +
geom_col() +
scale_x_reordered() +
facet_wrap(~character, scales = "free") +
coord_flip() +
theme(legend.position = "None")
library(tidyverse)
library(tidytext)
df <- read.csv("DemDebates.csv", colClasses = c("factor","factor","character"))
df <- df %>%
filter(!character %in% c("(Unknown)", "Announcer","Bash","Bridgewater","Burnett","Cooper","Davis","Diaz-Balart","Guthrie","Holt","Jose Diaz-Balart","Lacey","Lemon","Lester Holt", "Maddow","Muir","Protesters","Protestor","Ramos","Savannah Guthrie","Stephanopoulos","Tapper","Todd","Unknown"))
options(scipen = 999)
devtools::install_github("ricardo-bion/ggradar",
dependencies = TRUE)
install.packages("digest")
devtools::install_github("ricardo-bion/ggradar",
dependencies = TRUE)
remove.packages("digest")
devtools::install_github("ricardo-bion/ggradar",
dependencies = TRUE)
setwd("~/R work/SortingHat")
