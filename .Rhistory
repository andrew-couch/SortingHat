filter(!word %in% nameList$value,
!str_detect(word, pattern = "[[:digit:]]"),
!str_detect(word, pattern = "[[:punct:]]"),
!str_detect(word, pattern = "(.)\\1{2,}"),
!str_detect(word, pattern = "\\b(.)\\b"),) %>%
anti_join(stop_words) %>%
count(house, word, sort = TRUE) %>%
bind_tf_idf(word, house, n) %>%
group_by(house) %>%
top_n(tf_idf, n = 100)
df %>%
filter(house != "No Entry") %>%
get_sentences() %>%
unnest_tokens(word, "text") %>%
filter(!word %in% nameList$value,
!str_detect(word, pattern = "[[:digit:]]"),
!str_detect(word, pattern = "[[:punct:]]"),
!str_detect(word, pattern = "(.)\\1{2,}"),
!str_detect(word, pattern = "\\b(.)\\b"),) %>%
anti_join(stop_words) %>%
count(house, word, sort = TRUE) %>%
bind_tf_idf(word, house, n) %>%
group_by(house) %>%
top_n(tf_idf, n = 100) %>%
arrange(house, -tf_idf)
df %>%
filter(house != "No Entry") %>%
get_sentences() %>%
unnest_tokens(word, "text") %>%
filter(!word %in% nameList$value,
!str_detect(word, pattern = "[[:digit:]]"),
!str_detect(word, pattern = "[[:punct:]]"),
!str_detect(word, pattern = "(.)\\1{2,}"),
!str_detect(word, pattern = "\\b(.)\\b"),) %>%
anti_join(stop_words) %>%
count(house, word, sort = TRUE) %>%
bind_tf_idf(word, house, n) %>%
group_by(house) %>%
top_n(tf_idf, n = 100) %>%
arrange(house, -tf_idf) %>%
summary()
df %>%
filter(house != "No Entry") %>%
get_sentences() %>%
unnest_tokens(word, "text") %>%
filter(!word %in% nameList$value,
!str_detect(word, pattern = "[[:digit:]]"),
!str_detect(word, pattern = "[[:punct:]]"),
!str_detect(word, pattern = "(.)\\1{2,}"),
!str_detect(word, pattern = "\\b(.)\\b"),) %>%
anti_join(stop_words) %>%
count(house, word, sort = TRUE) %>%
bind_tf_idf(word, house, n) %>%
group_by(house) %>%
top_n(tf_idf, n = 100) %>%
tapply(., house, summary)
df %>%
filter(house != "No Entry") %>%
get_sentences() %>%
unnest_tokens(word, "text") %>%
filter(!word %in% nameList$value,
!str_detect(word, pattern = "[[:digit:]]"),
!str_detect(word, pattern = "[[:punct:]]"),
!str_detect(word, pattern = "(.)\\1{2,}"),
!str_detect(word, pattern = "\\b(.)\\b"),) %>%
anti_join(stop_words) %>%
count(house, word, sort = TRUE) %>%
bind_tf_idf(word, house, n) %>%
group_by(house) %>%
top_n(tf_idf, n = 100)
df %>%
filter(house != "No Entry") %>%
get_sentences() %>%
unnest_tokens(word, "text") %>%
filter(!word %in% nameList$value,
!str_detect(word, pattern = "[[:digit:]]"),
!str_detect(word, pattern = "[[:punct:]]"),
!str_detect(word, pattern = "(.)\\1{2,}"),
!str_detect(word, pattern = "\\b(.)\\b"),) %>%
anti_join(stop_words) %>%
count(house, word, sort = TRUE) %>%
bind_tf_idf(word, house, n) %>%
group_by(house) %>%
top_n(tf_idf, n = 100) %>%
select(house, tf_idf)
df %>%
filter(house != "No Entry") %>%
get_sentences() %>%
unnest_tokens(word, "text") %>%
filter(!word %in% nameList$value,
!str_detect(word, pattern = "[[:digit:]]"),
!str_detect(word, pattern = "[[:punct:]]"),
!str_detect(word, pattern = "(.)\\1{2,}"),
!str_detect(word, pattern = "\\b(.)\\b"),) %>%
anti_join(stop_words) %>%
count(house, word, sort = TRUE) %>%
bind_tf_idf(word, house, n) %>%
group_by(house) %>%
top_n(tf_idf, n = 100) %>%
select(house, tf_idf) %>%
tapply(., house, summary)
df %>%
filter(house != "No Entry") %>%
get_sentences() %>%
unnest_tokens(word, "text") %>%
filter(!word %in% nameList$value,
!str_detect(word, pattern = "[[:digit:]]"),
!str_detect(word, pattern = "[[:punct:]]"),
!str_detect(word, pattern = "(.)\\1{2,}"),
!str_detect(word, pattern = "\\b(.)\\b"),) %>%
anti_join(stop_words) %>%
count(house, word, sort = TRUE) %>%
bind_tf_idf(word, house, n) %>%
group_by(house) %>%
top_n(tf_idf, n = 100) %>%
select(house, tf_idf) %>%
tapply(., `house`, summary) %>%
df %>%
filter(house != "No Entry") %>%
get_sentences() %>%
unnest_tokens(word, "text") %>%
filter(!word %in% nameList$value,
!str_detect(word, pattern = "[[:digit:]]"),
!str_detect(word, pattern = "[[:punct:]]"),
!str_detect(word, pattern = "(.)\\1{2,}"),
!str_detect(word, pattern = "\\b(.)\\b"),) %>%
anti_join(stop_words) %>%
count(house, word, sort = TRUE) %>%
bind_tf_idf(word, house, n) %>%
group_by(house) %>%
top_n(tf_idf, n = 100) %>%
select(house, tf_idf) %>%
tapply(., `house`, summary)
df %>%
filter(house != "No Entry") %>%
get_sentences() %>%
unnest_tokens(word, "text") %>%
filter(!word %in% nameList$value,
!str_detect(word, pattern = "[[:digit:]]"),
!str_detect(word, pattern = "[[:punct:]]"),
!str_detect(word, pattern = "(.)\\1{2,}"),
!str_detect(word, pattern = "\\b(.)\\b"),) %>%
anti_join(stop_words) %>%
count(house, word, sort = TRUE) %>%
bind_tf_idf(word, house, n) %>%
group_by(house) %>%
top_n(tf_idf, n = 100) %>%
select(house, tf_idf) %>%
summarise(summary =  summary(.))
df %>%
filter(house != "No Entry") %>%
get_sentences() %>%
unnest_tokens(word, "text") %>%
filter(!word %in% nameList$value,
!str_detect(word, pattern = "[[:digit:]]"),
!str_detect(word, pattern = "[[:punct:]]"),
!str_detect(word, pattern = "(.)\\1{2,}"),
!str_detect(word, pattern = "\\b(.)\\b"),) %>%
anti_join(stop_words) %>%
count(house, word, sort = TRUE) %>%
bind_tf_idf(word, house, n) %>%
group_by(house) %>%
top_n(tf_idf, n = 100) %>%
select(house, tf_idf) %>%
summary()
df %>%
filter(house != "No Entry") %>%
get_sentences() %>%
unnest_tokens(word, "text") %>%
filter(!word %in% nameList$value,
!str_detect(word, pattern = "[[:digit:]]"),
!str_detect(word, pattern = "[[:punct:]]"),
!str_detect(word, pattern = "(.)\\1{2,}"),
!str_detect(word, pattern = "\\b(.)\\b"),) %>%
anti_join(stop_words) %>%
count(house, word, sort = TRUE) %>%
bind_tf_idf(word, house, n) %>%
group_by(house) %>%
top_n(tf_idf, n = 100) %>%
select(house, tf_idf) %>%
summarise(min = min(tf_idf),
q1 = quantile(tf_idf, .25),
median = median(tf_idf),
mean = mean(tf_idf),
q3 = quantile(tf_idf, .75),
max = max(tf_idf))
options(scipen = 10000)
df %>%
filter(house != "No Entry") %>%
get_sentences() %>%
unnest_tokens(word, "text") %>%
filter(!word %in% nameList$value,
!str_detect(word, pattern = "[[:digit:]]"),
!str_detect(word, pattern = "[[:punct:]]"),
!str_detect(word, pattern = "(.)\\1{2,}"),
!str_detect(word, pattern = "\\b(.)\\b"),) %>%
anti_join(stop_words) %>%
count(house, word, sort = TRUE) %>%
bind_tf_idf(word, house, n) %>%
group_by(house) %>%
top_n(tf_idf, n = 100) %>%
select(house, tf_idf) %>%
summarise(min = min(tf_idf),
q1 = quantile(tf_idf, .25),
median = median(tf_idf),
mean = mean(tf_idf),
q3 = quantile(tf_idf, .75),
max = max(tf_idf))
df %>%
filter(house != "No Entry") %>%
get_sentences() %>%
unnest_tokens(word, "text") %>%
filter(!word %in% nameList$value,
!str_detect(word, pattern = "[[:digit:]]"),
!str_detect(word, pattern = "[[:punct:]]"),
!str_detect(word, pattern = "(.)\\1{2,}"),
!str_detect(word, pattern = "\\b(.)\\b"),) %>%
anti_join(stop_words) %>%
count(house, word, sort = TRUE) %>%
bind_tf_idf(word, house, n) %>%
group_by(house) %>%
select(house, tf_idf) %>%
summarise(min = min(tf_idf),
q1 = quantile(tf_idf, .25),
median = median(tf_idf),
mean = mean(tf_idf),
q3 = quantile(tf_idf, .75),
max = max(tf_idf))
df %>%
filter(house != "No Entry") %>%
get_sentences() %>%
unnest_tokens(word, "text") %>%
filter(!word %in% nameList$value,
!str_detect(word, pattern = "[[:digit:]]"),
!str_detect(word, pattern = "[[:punct:]]"),
!str_detect(word, pattern = "(.)\\1{2,}"),
!str_detect(word, pattern = "\\b(.)\\b"),) %>%
anti_join(stop_words) %>%
count(house, word, sort = TRUE) %>%
bind_tf_idf(word, house, n) %>%
group_by(house) %>%
filter(tf_idf > mean(tf_idf)) %>%
select(house, tf_idf) %>%
summarise(min = min(tf_idf),
q1 = quantile(tf_idf, .25),
median = median(tf_idf),
mean = mean(tf_idf),
q3 = quantile(tf_idf, .75),
max = max(tf_idf))
df %>%
filter(house != "No Entry") %>%
get_sentences() %>%
unnest_tokens(word, "text") %>%
filter(!word %in% nameList$value,
!str_detect(word, pattern = "[[:digit:]]"),
!str_detect(word, pattern = "[[:punct:]]"),
!str_detect(word, pattern = "(.)\\1{2,}"),
!str_detect(word, pattern = "\\b(.)\\b"),) %>%
anti_join(stop_words) %>%
count(house, word, sort = TRUE) %>%
bind_tf_idf(word, house, n) %>%
group_by(house) %>%
filter(tf_idf >= mean(tf_idf)) %>%
select(house, tf_idf) %>%
summarise(min = min(tf_idf),
q1 = quantile(tf_idf, .25),
median = median(tf_idf),
mean = mean(tf_idf),
q3 = quantile(tf_idf, .75),
max = max(tf_idf))
df %>%
filter(house != "No Entry") %>%
get_sentences() %>%
unnest_tokens(word, "text") %>%
filter(!word %in% nameList$value,
!str_detect(word, pattern = "[[:digit:]]"),
!str_detect(word, pattern = "[[:punct:]]"),
!str_detect(word, pattern = "(.)\\1{2,}"),
!str_detect(word, pattern = "\\b(.)\\b"),) %>%
anti_join(stop_words) %>%
count(house, word, sort = TRUE) %>%
bind_tf_idf(word, house, n) %>%
group_by(house) %>%
filter(tf_idf >= mean(tf_idf)) %>%
nrow()
df %>%
filter(house != "No Entry") %>%
get_sentences() %>%
unnest_tokens(word, "text") %>%
filter(!word %in% nameList$value,
!str_detect(word, pattern = "[[:digit:]]"),
!str_detect(word, pattern = "[[:punct:]]"),
!str_detect(word, pattern = "(.)\\1{2,}"),
!str_detect(word, pattern = "\\b(.)\\b"),) %>%
anti_join(stop_words) %>%
count(house, word, sort = TRUE) %>%
bind_tf_idf(word, house, n) %>%
group_by(house) %>%
filter(tf_idf >= mean(tf_idf)) %>%
top_n(tf_idf, n = 100)
df %>%
filter(house != "No Entry") %>%
get_sentences() %>%
unnest_tokens(word, "text") %>%
filter(!word %in% nameList$value,
!str_detect(word, pattern = "[[:digit:]]"),
!str_detect(word, pattern = "[[:punct:]]"),
!str_detect(word, pattern = "(.)\\1{2,}"),
!str_detect(word, pattern = "\\b(.)\\b"),) %>%
anti_join(stop_words) %>%
count(house, word, sort = TRUE) %>%
bind_tf_idf(word, house, n) %>%
group_by(house) %>%
filter(tf_idf >= mean(tf_idf)) %>%
top_n(tf_idf, n = 100) %>%
nrow9)
df %>%
filter(house != "No Entry") %>%
get_sentences() %>%
unnest_tokens(word, "text") %>%
filter(!word %in% nameList$value,
!str_detect(word, pattern = "[[:digit:]]"),
!str_detect(word, pattern = "[[:punct:]]"),
!str_detect(word, pattern = "(.)\\1{2,}"),
!str_detect(word, pattern = "\\b(.)\\b"),) %>%
anti_join(stop_words) %>%
count(house, word, sort = TRUE) %>%
bind_tf_idf(word, house, n) %>%
group_by(house) %>%
filter(tf_idf >= mean(tf_idf)) %>%
top_n(tf_idf, n = 100) %>%
nrow()
df %>%
filter(house != "No Entry") %>%
get_sentences() %>%
unnest_tokens(word, "text") %>%
filter(!word %in% nameList$value,
!str_detect(word, pattern = "[[:digit:]]"),
!str_detect(word, pattern = "[[:punct:]]"),
!str_detect(word, pattern = "(.)\\1{2,}"),
!str_detect(word, pattern = "\\b(.)\\b"),) %>%
anti_join(stop_words) %>%
count(house, word, sort = TRUE) %>%
bind_tf_idf(word, house, n) %>%
group_by(house) %>%
filter(tf_idf >= mean(tf_idf)) %>%
top_n(tf_idf, n = 100) %>%
pull(word)
df %>%
filter(house != "No Entry") %>%
get_sentences() %>%
unnest_tokens(word, "text") %>%
filter(!word %in% nameList$value,
!str_detect(word, pattern = "[[:digit:]]"),
!str_detect(word, pattern = "[[:punct:]]"),
!str_detect(word, pattern = "(.)\\1{2,}"),
!str_detect(word, pattern = "\\b(.)\\b"),) %>%
anti_join(stop_words) %>%
count(house, word, sort = TRUE) %>%
bind_tf_idf(word, house, n) %>%
group_by(house) %>%
filter(tf_idf >= mean(tf_idf)) %>%
top_n(tf_idf, n = 100) %>%
pull(word) %>% nrow()
df %>%
filter(house != "No Entry") %>%
get_sentences() %>%
unnest_tokens(word, "text") %>%
filter(!word %in% nameList$value,
!str_detect(word, pattern = "[[:digit:]]"),
!str_detect(word, pattern = "[[:punct:]]"),
!str_detect(word, pattern = "(.)\\1{2,}"),
!str_detect(word, pattern = "\\b(.)\\b"),) %>%
anti_join(stop_words) %>%
count(house, word, sort = TRUE) %>%
bind_tf_idf(word, house, n) %>%
group_by(house) %>%
filter(tf_idf >= mean(tf_idf)) %>%
top_n(tf_idf, n = 100) %>%
pull(word) %>% length()
df %>%
filter(house != "No Entry") %>%
get_sentences() %>%
unnest_tokens(word, "text") %>%
filter(!word %in% nameList$value,
!str_detect(word, pattern = "[[:digit:]]"),
!str_detect(word, pattern = "[[:punct:]]"),
!str_detect(word, pattern = "(.)\\1{2,}"),
!str_detect(word, pattern = "\\b(.)\\b"),) %>%
anti_join(stop_words) %>%
count(house, word, sort = TRUE) %>%
bind_tf_idf(word, house, n) %>%
group_by(house) %>%
filter(tf_idf >= mean(tf_idf)) %>%
top_n(tf_idf, n = 100) %>%
pull(word) %>% unique() %>% length()
df %>%
filter(house != "No Entry") %>%
get_sentences() %>%
unnest_tokens(word, "text") %>%
filter(!word %in% nameList$value,
!str_detect(word, pattern = "[[:digit:]]"),
!str_detect(word, pattern = "[[:punct:]]"),
!str_detect(word, pattern = "(.)\\1{2,}"),
!str_detect(word, pattern = "\\b(.)\\b"),) %>%
anti_join(stop_words) %>%
count(house, word, sort = TRUE) %>%
bind_tf_idf(word, house, n) %>%
group_by(house) %>%
filter(tf_idf >= mean(tf_idf)) %>%
top_n(tf_idf, n = 100) %>%
pull(word) %>%
unique() %>% length()
df %>%
filter(house != "No Entry") %>%
get_sentences() %>%
unnest_tokens(word, "text") %>%
filter(!word %in% nameList$value,
!str_detect(word, pattern = "[[:digit:]]"),
!str_detect(word, pattern = "[[:punct:]]"),
!str_detect(word, pattern = "(.)\\1{2,}"),
!str_detect(word, pattern = "\\b(.)\\b"),) %>%
anti_join(stop_words) %>%
count(house, word, sort = TRUE) %>%
bind_tf_idf(word, house, n) %>%
group_by(house) %>%
top_n(tf_idf, n = 100) %>%
pull(word) %>%
unique() %>% length()
df %>%
get_sentences()
df %>%
get_sentences() %>%
get_sentiments(lexicon = c("afinn", "bing", "nrc"))
?get_sentiments
df %>%
get_sentences() %>%
inner_join(get_sentiments(lexicon = c("afinn", "bing", "nrc")))
inner_join(get_sentiments(lexicon = "nrc")
df %>%
get_sentences() %>%
inner_join(get_sentiments(lexicon = "nrc"))
df %>%
get_sentences() %>%
unnest_tokens(word, "text") %>%
anti_join(stop_words) %>%
inner_join(get_sentiments(lexicon = "nrc"))
df %>%
get_sentences() %>%
unnest_tokens(word, "text") %>%
anti_join(stop_words) %>%
inner_join(get_sentiments(lexicon = "bing"))
df %>%
get_sentences() %>%
unnest_tokens(word, "text") %>%
anti_join(stop_words) %>%
inner_join(get_sentiments(lexicon = "bing")) %>%
group_by(book,character, sentiment) %>%
count(sentiment)
df %>%
get_sentences() %>%
unnest_tokens(word, "text") %>%
anti_join(stop_words) %>%
inner_join(get_sentiments(lexicon = "bing")) %>%
group_by(book,character, sentiment) %>%
count(sentiment)
get_sentiments(lexicon = "bing")
df %>%
get_sentences() %>%
unnest_tokens(word, "text") %>%
anti_join(stop_words) %>%
inner_join(get_sentiments(lexicon = "bing")) %>%
group_by(book,character, sentiment) %>%
count(sentiment)
df %>%
get_sentences() %>%
unnest_tokens(word, "text") %>%
anti_join(stop_words) %>%
inner_join(get_sentiments(lexicon = "bing")) %>%
group_by(book,character, sentence_id, sentiment) %>%
count(sentiment)
df %>%
get_sentences() %>%
unnest_tokens(word, "text") %>%
anti_join(stop_words) %>%
inner_join(get_sentiments(lexicon = "bing")) %>%
group_by(book,character, element_id,sentence_id, sentiment) %>%
count(sentiment)
df %>%
get_sentences() %>%
unnest_tokens(word, "text") %>%
anti_join(stop_words) %>%
inner_join(get_sentiments(lexicon = "bing")) %>%
group_by(book,character, element_id,sentence_id, sentiment) %>%
count(sentiment) %>%
spread(sentiment)
df %>%
get_sentences() %>%
unnest_tokens(word, "text") %>%
anti_join(stop_words) %>%
inner_join(get_sentiments(lexicon = "bing")) %>%
group_by(book,character, element_id,sentence_id, sentiment) %>%
count(sentiment) %>%
spread(sentiment, n)
df %>%
get_sentences() %>%
unnest_tokens(word, "text") %>%
anti_join(stop_words) %>%
inner_join(get_sentiments(lexicon = "bing")) %>%
group_by(book,character, element_id,sentence_id, sentiment) %>%
count(sentiment) %>%
spread(sentiment, n, fill = 0)
