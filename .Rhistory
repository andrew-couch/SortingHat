theme(legend.position = "top",
legend.justification = "center",
plot.title = element_text(hjust = .5))
library(tidyverse)
library(caret)
library(tidyverse)
library(caret)
df <- iris
svm <- train(Species~., data = df, method = "svmLinear")
svm <- train(Species~., data = df, method = "svmLinear")
install.packages("e1071")
svm <- train(Species~., data = df, method = "svmLinear")
plot(svm)
svm
svm %>% plot()
svm %>% plotClassProbs()
library(tidyverse)
library(caret)
df <- iris
svm <- train(Species~., data = df, method = "svmLinear")
kernlab::plot(svm)
kernlab::plot.kvsm?
kernlab::plot.kvsm
?kernlab::plot.kvsm
?plot.kvsm
library(tidyverse)
library(tidyverse)
library(tidytext)
library(sentimentr)
df <- read.csv("harrypotter.csv")
df$text <- as.character(df$text)
nameList <- read.csv("namelist.csv")
#This section creates ngram features
#The features will be grouped by character
#Characters are different for each medium there's a movie_harry and book_harry
#May group characters by medium and book which would be Chamber_Of_Secrets_Movie_Harry
#Creates word list for bag of words feature
wordList <- df %>%
select(text) %>%
unnest_tokens(word, "text") %>%
anti_join(stop_words) %>%
filter(!str_detect(word, pattern = "[[:digit:]]"),
!str_detect(word, pattern = "[[:punct:]]"),
!str_detect(word, pattern = "(.)\\1{2,}"),
!str_detect(word, pattern = "\\b(.)\\b")) %>%
count(word, sort = TRUE) %>%
filter(n > 10) %>%
pull(word)
#generates bag of words features
bowFeatures <- df %>%
unnest_tokens(word, "text") %>%
anti_join(stop_words) %>%
filter(word %in%  wordList) %>%
count(character, word) %>%
spread(word, n) %>%
map_df(replace_na, 0)
#creates bigram list for bigram features
bigramList <- df %>%
select(text) %>%
unnest_tokens(bigram, "text", token = "ngrams", n = 2) %>%
separate(bigram, c("word1", "word2"), sep = " ") %>%
filter(!word1 %in% stop_words$word,
!word2 %in% stop_words$word,
!str_detect(word1, pattern = "[[:digit:]]"),
!str_detect(word2, pattern = "[[:digit:]]"),
!str_detect(word1, pattern = "[[:punct:]]"),
!str_detect(word2, pattern = "[[:punct:]]"),
!str_detect(word1, pattern = "(.)\\1{2,}"),
!str_detect(word2, pattern = "(.)\\1{2,}"),
!str_detect(word1, pattern = "\\b(.)\\b"),
!str_detect(word1, pattern = "\\b(.)\\b")) %>%
unite("bigram", c(word1, word2), sep = " ") %>%
count(bigram) %>%
filter(n > 2) %>%
pull(bigram)
#creates bigram features
bigramFeatures <- df %>%
unnest_tokens(bigram, "text", token = "ngrams", n = 2) %>%
filter(bigram %in% bigramList) %>%
count(character, bigram) %>%
spread(bigram, n) %>%
map_df(replace_na, 0)
#creates trigram list for trigram features
trigramList <- df %>%
unnest_tokens(trigram, "text", token = "ngrams", n = 3) %>%
separate(trigram, c("word1","word2","word3"), sep = " ") %>%
filter(!word1 %in% stop_words$word,
!str_detect(word1, pattern = "[[:digit:]]"),
!str_detect(word1, pattern = "[[:punct:]]"),
!str_detect(word1, pattern = "(.)\\1{2,}"),
!str_detect(word1, pattern = "\\b(.)\\b"),
!word2 %in% stop_words$word,
!str_detect(word2, pattern = "[[:digit:]]"),
!str_detect(word2, pattern = "[[:punct:]]"),
!str_detect(word2, pattern = "(.)\\1{2,}"),
!str_detect(word2, pattern = "\\b(.)\\b"),
!word3 %in% stop_words$word,
!str_detect(word3, pattern = "[[:digit:]]"),
!str_detect(word3, pattern = "[[:punct:]]"),
!str_detect(word3, pattern = "(.)\\1{2,}"),
!str_detect(word3, pattern = "\\b(.)\\b")) %>%
unite("trigram", c(word1, word2, word3), sep = " ") %>%
count(trigram) %>%
filter(n > 2) %>%
pull(trigram)
#creates trigram features
trigramFeatures <- df %>%
unnest_tokens(trigram, "text", token = "ngrams", n = 3) %>%
filter(trigram %in% trigramList) %>%
count(character, trigram) %>%
spread(trigram, n) %>%
map_df(replace_na,0)
#This section creates lexicon sentiment analysis features
#data will need to be processed on a sentence level using sentimentR
#This section will add an tf-idf feature (term frequency and inverse document frequency)
#Where document will be each movie or book
#Weights words and may help separating the houses
tf_idfWOrdList <- df %>%
filter(house != "No Entry") %>%
get_sentences() %>%
unnest_tokens(word, "text") %>%
filter(!word %in% nameList$value,
!str_detect(word, pattern = "[[:digit:]]"),
!str_detect(word, pattern = "[[:punct:]]"),
!str_detect(word, pattern = "(.)\\1{2,}"),
!str_detect(word, pattern = "\\b(.)\\b"),
!word %in% stop_words$word) %>%
count(house, word, sort = TRUE) %>%
bind_tf_idf(word, house, n) %>%
filter(tf_idf > median(tf_idf)) %>%
pull(word)
library(rattle)
rattle()
library(rattle)
rattle()
df <- read.csv("UI_ISU.csv")
df$Iowa[20] <- 18
df$ISU[20] <- 17
df$margin <- abs(df$Iowa - df$ISU)
df$IowaWin <- df$Iowa > df$ISU
df$IowaWin <- as.factor(df$IowaWin)
df$IowaWin <- as.integer(df$IowaWin)
library(tidytext)
library(tidyverse)
df <- "I like dogs. I like cats."
library(tidytext)
library(tidyverse)
df <- "I like dogs. I like cats."
df %>% sentences
sentences
df %>% unnest_tokens(sentence)
df %>% unnest_tokens(sentence, token = "sentences")
unnest_tokens(sentence, "I like dogs. I like cats.",token = "sentences")
unnest_tokens(sentence, "I like dogs. I like cats.",token = "sentences")
unnest_tokens("I like dogs. I like cats.",token = "sentences")
df %>% as.data.frame()
df <- df %>% as.data.frame()
unnest_tokens(sentence, df,token = "sentences")
unnest_tokens(sentence, df ,token = "sentences")
unnest_tokens( df ,token = "sentences")
df %>% unnest_tokens(sentence, df$., token = "sentences")
df <- data.frame("text" = "I like cats. I like dogs. I hate humans.")
View(df)
df %>% unnest_tokens(sentence, "text", token = "sentences")
df %>% unnest_tokens(sentence, "text", token = "sentences") %>%
unnest_tokens(word, "sentence", token = "words")
df %>% unnest_tokens(sentence, "text", token = "sentences") %>%
unnest_tokens(word, "sentence", token = "words") %>%
count(word)
df %>% unnest_tokens(sentence, "text", token = "sentences") %>%
unnest_tokens(word, "sentence", token = "words") %>%
count(word)
df %>% unnest_tokens(sentence, "text", token = "sentences")
df %>% unnest_tokens(sentence, "text", token = "sentences") %>% view()
df <- data.frame("text" = c("I like dogs.","I like cats.","I hate turtles.","I like turtles."))
View(df)
df %>% unnest_tokens(sentence, "text", token = "sentences")
df %>% unnest_tokens(sentence, "text", token = "sentences") %>% view()
df %>% unnest_tokens(word, "text", token = "words")
df %>% unnest_tokens(word, "text", token = "word")
df %>% unnest_tokens(word, "text", token = "words")
df %>% unnest_tokens(word, "text")
df %>% unnest_tokens(word, "text")
df
df %>% unnest_tokens(word, "text")
df %>% unnest_tokens(word, text)
str(df)
df %>% as.character()
df$text <- df$text %>% as.character()
df %>% unnest_tokens(word, text)
df %>% unnest_tokens(word, text) %>% view()
df <- data.frame("text" = c("I like dogs.","I like cats.","I hate turtles.","I like turtles."), line = 1:4)
df$text <- df$text %>% as.character()
df %>% unnest_tokens(word, text) %>% view()
df %>%
unnest_tokens(word, text) %>%
count(line, word) %>%
bind_tf_idf(word,line,n)
df %>%
unnest_tokens(word, text) %>%
count(line, word) %>%
bind_tf_idf(word,line,n) %>%
filter(tf_idf != 0)
df %>%
unnest_tokens(word, text) %>%
count(line, word) %>%
bind_tf_idf(word, line, n) %>%
filter(tf_idf != 0)
df %>%
unnest_tokens(word, text) %>%
count(line, word) %>%
bind_tf_idf(word, line, n) %>%
filter(tf_idf != 0) %>%
arrange(line)
df %>%
unnest_tokens(word, text) %>%
count(line,word) %>%
group_by(line) %>%
top_n(n,n=2)
df %>%
unnest_tokens(word, text) %>%
count(line,word) %>%
arrange(line)
df %>%
unnest_tokens(word, text) %>%
count(line, word) %>%
bind_tf_idf(word, line, n) %>%
filter(tf_idf != 0) %>%
arrange(line)
df %>%
unnest_tokens(word, text) %>%
count(line,word) %>%
arrange(line)
.333/1.39
df <- data.frame("text" = c("I like dogs.",
"I like cats.",
"I like turtles.",
"I like penguins."), line = 1:4)
df$text <- df$text %>% as.character()
df %>%
unnest_tokens(word, text) %>%
count(line, word) %>%
bind_tf_idf(line, word, n)
df %>%
unnest_tokens(word, text) %>%
count(line, word) %>%
bind_tf_idf(word, line, n)
df %>%
unnest_tokens(word, text) %>%
count(line, word) %>%
bind_tf_idf(word, line, n) %>%
filter(tf_idf != 0)
df %>%
unnest_tokens(word, text) %>%
count(line, word) %>%
bind_tf_idf(word, line, n) %>%
filter(tf_idf != 0)
df %>%
unnest_tokens(word,text) %>%
count(line,word)
df %>%
unnest_tokens(word, text) %>%
count(line, word) %>%
bind_tf_idf(word, line, n) %>%
filter(tf_idf != 0)
df <- data.frame("text" = c("I like dogs.",
"I like cats.",
"I like turtles.",
"I like penguins.",
"I hate dogs",
"I hate cats",
"I hate turtles",
"I hate penguins"), line = 1:8)
df$text <- df$text %>% as.character()
df %>%
unnest_tokens(word, text) %>%
count(line, word) %>%
bind_tf_idf(word, line, n) %>%
filter(tf_idf != 0)
df %>%
unnest_tokens(word, text) %>%
count(line, word) %>%
bind_tf_idf(word, line, n) %>%
filter(tf_idf != 0) %>%
group_by(line) %>%
filter(tf_idf = max(tf_idf))
df %>%
unnest_tokens(word, text) %>%
count(line, word) %>%
bind_tf_idf(word, line, n) %>%
filter(tf_idf != 0) %>%
group_by(line) %>%
filter(tf_idf == max(tf_idf))
df %>%
unnest_tokens(word, text) %>%
count(line, word) %>%
bind_tf_idf(word, line, n) %>%
filter(tf_idf != 0) %>%
group_by(line)
df %>%
unnest_tokens(word, text) %>%
count(line, word) %>%
bind_tf_idf(word, line, n) %>%
filter(tf_idf != 0) %>%
group_by(line) %>%
arrange(line, tf_idf)
df %>%
unnest_tokens(word, text) %>%
count(line, word) %>%
bind_tf_idf(word, line, n) %>%
filter(tf_idf != 0) %>%
group_by(line) %>%
arrange(line, -tf_idf)
df %>%
unnest_tokens(word, text) %>%
count(line, word) %>%
bind_tf_idf(word, line, n) %>%
filter(tf_idf != 0) %>%
group_by(line) %>%
arrange(word)
df %>%
unnest_tokens(word, text) %>%
count(line, word) %>%
bind_tf_idf(word, line, n) %>%
filter(tf_idf != 0) %>%
group_by(line) %>%
arrange(tf_idf)
df %>%
unnest_tokens(word, text) %>%
count(line, word) %>%
bind_tf_idf(word, line, n) %>%
group_by(line) %>%
arrange(tf_idf)
df %>%
unnest_tokens(word, text) %>%
count(line, word) %>%
bind_tf_idf(word, line, n) %>%
group_by(line) %>%
arrange(-tf_idf)
df %>%
unnest_tokens(word, text) %>%
count(line, word) %>%
bind_tf_idf(word, line, n) %>%
group_by(line)
df <- data.frame("character" = c("John","John","John","John","Mary","Mary","Mary","Mary"),
"text" = c("I like dogs.",
"I like cats.",
"I like turtles.",
"I like penguins.",
"I hate dogs",
"I hate cats",
"I hate turtles",
"I hate penguins"), line = 1:8)
df$text <- df$text %>% as.character()
df %>%
unnest_tokens(word, text) %>%
count(line, word) %>%
bind_tf_idf(word, line, n) %>%
group_by(line)
df %>%
unnest_tokens(word, text) %>%
count(character, word) %>%
bind_tf_idf(word, character, n) %>%
group_by(line)
df %>%
unnest_tokens(word, text) %>%
count(character, word) %>%
bind_tf_idf(word, character, n) %>%
group_by(character)
df %>%
unnest_tokens(word, text) %>%
count(character, word) %>%
bind_tf_idf(word, character, n) %>%
group_by(character) %>%
top_n(tf_idf, n = 1)
df %>% unnest_tokens(word,text) %>%
count(character, word)
df %>% unnest_tokens(word,text) %>%
count(character, word) %>%
top_n(n, n =1)
df %>% unnest_tokens(word,text) %>%
count(character, word) %>%
group_by(character) %>%
top_n(n, n =1)
(tf_idf, n = 1)
df %>%
unnest_tokens(word, text) %>%
count(character, word) %>%
bind_tf_idf(word, character, n) %>%
group_by(character) %>%
top_n(tf_idf, n = 1)
df %>% unnest_tokens(word,text) %>%
count(character, word) %>%
group_by(character) %>%
top_n(n, n =1)
library(rattle)
rattle()
library(rattle)
rattle()
library(caret)
library(tidyverse)
iris
model <- train(Species~.,
data = iris,
method = "rf",
trCOntrol = trainControl(method = "boot",
classProbs = TRUE,
summaryFunction = multiClassSummary))
model
multiClassSummary(model)
multiClassSummary(model$pred)
multiClassSummary(model$pred, model$results)
?multiClassSummary
model$pred
model$finalModel$predicted
model$finalModel$y
model$finalModel$obsLevels
multiClassSummary(iris,model$finalModel$obsLevels, model)
multiClassSummary(iris,model$finalModel$obsLevels, model)
model$finalModel
model$finalModel$confusion
confusionMatrix(model)
model
model <- train(Species~.,
data = iris,
method = "rf",
trCOntrol = trainControl(method = "boot",
classProbs = TRUE,
summaryFunction = multiClassSummary),
metric = "recall")
extractProb(model)
extractProb(model$finalModel)
predict(model, iris, type = "prob")
predict(model, iris, type = "prob") %>% cbind(iris$Species)
library(rattle)
rattle()
library(rattle)
rattle()
mtcars
df <- mtcars
df$efficient <- ifelse(df$mpg <20, 0,1)
df$efficient2 <- as.numeric(df$mpg < 20)
df$efficient
df$efficient2
df$efficient2 <- as.numeric(df$mpg >= 20)
df$efficient2
df$mpg
View(df)
df <- mtcars
df$efficient <- ifelse(df$mpg <20, 0,1)
df$efficient2 <- as.numeric(df$mpg >= 20)
str(df)
library(tidyverse)
library(caret)
iris
logModel <- train(Species~., data = iris, method = "logreg")
logModel <- train(Species~., data = iris, method = "logreg")
df <- iris
df
logModel <- train(Species~., data = df, method = "logreg")
modelLookup("logreg")
df %>% filter(Species == c("virginica", "setosa"))
test <- df %>% filter(Species == c("virginica", "setosa"))
logModel <- train(Species~., data = test, method = "logreg")
test
logModel <- train(Species~., data = test %>% na.omit(), method = "logreg")
test %>% str()
logModel <- train(Species~., data = df %>% na.omit(), method = "logreg")
warnings()
logModel <- train(Species~., data = df, method = "glm")
logModel <- train(Species~., data = df, method = "multinom")
logModel
plot(logModel)
modelLookup("multinom")
library(tidyverse)
library(caret)
setwd("~/R work/SortingHat")
df <- readRDS("harrypotter.csv")
df <- readRDS("harrypotter.rds")
library(tidyverse)
library(caret)
df <- readRDS("harrypotter.rds")
str(df)
df$character <- NULL
df %>% str()
df$TargetHouse <- as.factor(df$TargetHouse)
upSample <- upSample(df %>% select(-TargetHouse), df$TargetHouse)
baseLineModel <- train(Class~., data = upSample, method = 'multinom')
warnings()
View(upSample)
trainIndex <- createDataPartition(upSample$Class, p = 2/3, list = FALSE)
trainData <- upSample[trainIndex,]
testData <- upSample[-trainIndex,]
baseLineModel <- train(Class~., data = trainData %>% head(), method = 'multinom')
baseLineModel <- train(Class~., data = trainData[1:100,], method = 'multinom')
baseLineModel <- train(Class~., data = trainData, method = 'multinom')
library(tidyverse)
library(caret)
df <- readRDS("harrypotter.rds")
df$character <- NULL
df$TargetHouse <- as.factor(df$TargetHouse)
upSample <- upSample(df %>% select(-TargetHouse), df$TargetHouse)
trainIndex <- createDataPartition(upSample$Class, p = 2/3, list = FALSE)
trainData <- upSample[trainIndex,]
testData <- upSample[-trainIndex,]
baseLineModel <- train(Class~., data = trainData, method = 'multinom')
baseLineModel
trainData$Class %>% group_by(Class) %>% count()
trainData$Class %>% count()
trainData$Class
trainData$Class %>%
unique()
