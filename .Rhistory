#Reads in twitter API token
token <- get_token()
View(token)
token
get_timeline("npr", n = 1)
#Reads in twitter API token
token <- create_token(app = "Iowa City Tweeter",
consumer_key = "PQOYgnw75Mgu1j5dR0slZX9nz",
consumer_secret = "2RJbRMLQ9cAg0YAWNA5VK4WRUWESTWD2z7jBxSgBiTHOCSv2R5",
access_token = "810563027791712261-hToHJ9UVNvLE5EAYNHet9RuWw0tqoZK",
access_secret = "fphVef0J3RwmCYudR9eEnY7VC58RGuajhkFIEZ0SfnBzj")
get_timeline("npr", n = 1)
library(tidyverse)
library(rtweet)
library(tidytext)
library(sentimentr)
library(doParallel)
library(ggrepel)
library(ggthemes)
rm(list = ls())
get_token()
get_token()
userName <- "senwarren"
#Reads in Document Term Matrix
bow <- read.csv("bowlist.csv", header = TRUE,stringsAsFactors = FALSE)
bigram <- read.csv("bigramlist.csv", header = TRUE,stringsAsFactors = FALSE)
trigram <- read.csv("trigramlist.csv", header = TRUE,stringsAsFactors = FALSE)
#Reads in twitter API token
#Retrieves tweets from username
myTweets <- get_timeline(userName, n = 3200)
#Enables parallel computing for faster compile times
cl <- makePSOCKcluster(7)
registerDoParallel(cl)
StartTime <- Sys.time()
#Cleans data by removing @Names, links, and Retweets
tweetData <- myTweets %>%
filter(is_retweet == FALSE) %>%
select(text) %>%
mutate(userName = userName)
tweetData$text <- str_trim(gsub('http\\S+\\s*',"", tweetData$text))
tweetData$text <- gsub("(^|[^@\\w])@(\\w{1,15})\\b", "", tweetData$text)
tweetData <- tweetData %>%
filter(!text %in% c(" ", "", "   "))
#Generate BOW, Bigram,and Trigram Features
bowFeatures <- tweetData %>%
unnest_tokens(word, "text") %>%
filter(word != "tweet") %>%
right_join(bow, by = c("word" = "bow")) %>%
count(word, word) %>%
mutate(n = n-1) %>%
spread(word, n)
bigramFeatures <- tweetData %>%
unnest_tokens(bigram, "text", token = "ngrams", n = 2) %>%
right_join(bigram, by = c("bigram" = "bigram")) %>%
count(bigram, bigram) %>%
mutate(n = n-1) %>%
spread(bigram, n)
trigramFeatures <- tweetData %>%
unnest_tokens(trigram, "text", token = "ngrams", n = 3) %>%
right_join(trigram, by = c("trigram" = "trigram")) %>%
count(trigram, trigram) %>%
mutate(n = n-1) %>%
spread(trigram, n)
#Generate positive negative sentiment features
sentences <- tweetData %>% select(text) %>% get_sentences()
sentiments <- cbind(
sentences %>%
sentiment((lexicon::hash_sentiment_huliu)) %>%
select(sentiment) %>%
rename("huliu" = sentiment),
sentences %>%
sentiment(lexicon::hash_sentiment_jockers_rinker) %>%
select(sentiment) %>%
rename("jockers_rinker" = sentiment),
sentences %>%
sentiment(lexicon::hash_sentiment_nrc) %>%
select(sentiment) %>%
rename("nrc" = sentiment),
sentences %>%
sentiment(lexicon::hash_sentiment_senticnet) %>%
select(sentiment) %>%
rename("senticnet" = sentiment),
sentences %>%
sentiment(lexicon::hash_sentiment_sentiword) %>%
select(sentiment) %>%
rename("sentiword" = sentiment),
sentences %>%
sentiment(lexicon::hash_sentiment_slangsd) %>%
select(sentiment) %>%
rename("slangsd" = sentiment),
sentences %>%
sentiment(lexicon::hash_sentiment_socal_google) %>%
select(sentiment) %>%
rename("socal_google" = sentiment))
sentiments <-  sentiments %>%
gather(key = "sentiment", value = "score") %>%
group_by(sentiment) %>%
summarise(score = mean(score)) %>%
spread(key = sentiment, value = score)
#Generates emotion sentiment features such as anger, anticipation, disgust, fear, joy, sadness, surprise, and trust
emotions <- lexicon::nrc_emotions
emotionFeatures <- sentences %>%
unnest_tokens(word, "text") %>%
filter(word %in% emotions$term) %>%
left_join(emotions, by = c("word" = "term")) %>%
select(-word,-element_id, -sentence_id) %>%
summarise_each(funs(sum)) %>%
gather(key = "sentiment", value = "score") %>%
mutate(score = score / sentences %>% unnest_tokens(word, "text") %>% nrow()) %>%
spread(sentiment, score) %>%
rename("anger.emotion" = anger,
"anticipation.emotion" = anticipation,
"digust.emotion" = disgust,
"fear.emotion" = fear,
"joy.emotion" = joy,
"sadness.emotion" = sadness,
"surprise.emotion" = surprise,
"trust.emotion" = trust)
#Combines BOW, Bigram, Trigram, Sentiment, and Emotion features
df <- cbind(bowFeatures, bigramFeatures, trigramFeatures, sentiments, emotionFeatures)
#Reads in models
LogisticRegressionModel <- readRDS("LogisticRegressionModel.rds")
NaiveBayesModel <- readRDS("NaiveBayesModel.rds")
L1Model <- readRDS("L1Model.rds")
L2Model <- readRDS("L2Model.rds")
ElasticNetModel <- readRDS("ElasticNetModel.rds")
MARSModel <- readRDS("MARSModel.rds")
KnnModel <- readRDS("KnnModel.rds")
RandomForestModel <- readRDS("RandomForestModel.rds")
SVMModel <- readRDS("SupportVectorMachineModel.rds")
EnsembleModel <- readRDS("EnsembleModel.rds")
#Generates data for esemble model
ensembleData <- cbind(predict(LogisticRegressionModel, df, type = "prob"),
predict(NaiveBayesModel, df, type = "prob"),
predict(L1Model, df, type = "prob"),
predict(L2Model,df, type = "prob"),
predict(ElasticNetModel, df, type = "prob"),
predict(MARSModel, df, type = "prob"),
predict(KnnModel, df, type = "prob"),
predict(RandomForestModel, df, type = "prob"),
predict(SVMModel, df, type = "prob"))
colnames(ensembleData) <- c("LogisticGryffindor","LogisticHufflepuff","LogisticRavenclaw","LogisticSlytherin",
"NaiveBayesGryffindor","NaiveBayesHufflepuff","NaiveBayesRavenclaw","NaiveBayesSlytherin",
"L1Gryffindor","L1Hufflepuff","L1Ravenclaw","L1Slytherin",
"L2Gryffindor","L2Hufflepuff","L2Ravenclaw","L2Slytherin",
"ElasticNetGryffindor","ElasticNetHufflepuff","ElasticNetRavenclaw","ElasticNetSlytherin",
"MARSGryffindor","MARSHufflepuff","MARSRavenclaw","MARSSlytherin",
"KNNGryffindor","KNNHufflepuff","KNNRavenclaw","KNNSlytherin",
"RandomForestGryffindor","RandomForestHufflepuff","RandomForestRavenclaw","RandomForestSlytherin",
"SVMGryffindor","SVMHufflepuff","SVMRavenclaw","SVMSlytherin")
#Uses ensemble model to make final prediction
HousePrediction <- predict(EnsembleModel, ensembleData, type = "prob")
colnames(HousePrediction) <- c("Gryffindor", "Hufflepuff", "Ravenclaw", "Slytherin")
#Stops parallel computing
stopCluster(cl)
EndTime <- Sys.time()
StartTime - EndTime
#Plots predictions as probabilities/percentage
HousePrediction %>%
gather(key = "House", value = "Percentage") %>%
ggplot(aes(x = House,
y = Percentage,
color = House,
fill = House)) +
geom_col() +
scale_y_continuous(labels = scales::percent) +
ggtitle(paste(userName, "'s House Assignment", sep = "")) +
theme(plot.title = element_text(hjust = .5)) +
theme_economist()
HousePrediction %>%
mutate("Name" = userName) %>%
write.table("SortingHatList.csv",
row.names = FALSE,
col.names = FALSE,
sep = ",",
append = TRUE)
sortedList <- read.csv("SortingHatList.csv")
exampleNames <- sortedList %>%
gather(key = "house", value = "value", -Name) %>%
group_by(Name) %>%
top_n(value, n =1) %>%
select(Name, house) %>%
inner_join(sortedList) %>%
mutate(x = Hufflepuff - Ravenclaw,
y = Gryffindor - Slytherin) %>%
select(Name, x , y, house) %>%
filter(Name %in% c("Book_Harry", "Book_Malfoy" ,userName))
sortedList %>%
gather(key = "house", value = "value", -Name) %>%
group_by(Name) %>%
top_n(value, n =1) %>%
select(Name, house) %>%
inner_join(sortedList) %>%
mutate(x = Hufflepuff - Ravenclaw,
y = Gryffindor - Slytherin) %>%
select(Name, x , y, house) %>%
ggplot(aes(x = x, y = y, label = Name)) +
geom_vline(xintercept = 0, linetype = "dashed", alpha = .5) +
geom_hline(yintercept = 0, linetype = "dashed", alpha = .5) +
geom_point(aes(color = house)) +
geom_text_repel(data = exampleNames,
mapping = aes(x = x, y = y, label = Name),
nudge_x = .1) +
theme_fivethirtyeight() +
theme(aspect.ratio = 1, axis.title = element_text()) +
ylab(expression("More likely Slytherin  " %<->% " More likely Gryffindor")) +
xlab(expression("More likely Ravenclaw  " %<->% " More likely Hufflepuff"))
#install.packages(tidyverse)
#install.packages(rtweet)
#install.packages(tidytext)
#install.packages(sentimentr)
#install.packages(doParallel)
#install.packages(caret)
#install.packages(ggthemes)
library(tidyverse)
library(rtweet)
library(tidytext)
library(sentimentr)
library(doParallel)
library(ggrepel)
library(ggthemes)
rm(list = ls())
get_token()
#Twitter username for sorting hat
userName <- "senwarren"
#Reads in Document Term Matrix
bow <- read.csv("bowlist.csv", header = TRUE,stringsAsFactors = FALSE)
bigram <- read.csv("bigramlist.csv", header = TRUE,stringsAsFactors = FALSE)
trigram <- read.csv("trigramlist.csv", header = TRUE,stringsAsFactors = FALSE)
#Retrieves tweets from username
myTweets <- get_timeline(userName, n = 3200)
#Enables parallel computing for faster compile times
cl <- makePSOCKcluster(7)
registerDoParallel(cl)
StartTime <- Sys.time()
#Cleans data by removing @Names, links, and Retweets
tweetData <- myTweets %>%
filter(is_retweet == FALSE) %>%
select(text) %>%
mutate(userName = userName)
tweetData$text <- str_trim(gsub('http\\S+\\s*',"", tweetData$text))
tweetData$text <- gsub("(^|[^@\\w])@(\\w{1,15})\\b", "", tweetData$text)
tweetData <- tweetData %>%
filter(!text %in% c(" ", "", "   "))
#Generate BOW, Bigram,and Trigram Features
bowFeatures <- tweetData %>%
unnest_tokens(word, "text") %>%
filter(word != "tweet") %>%
right_join(bow, by = c("word" = "bow")) %>%
count(word, word) %>%
mutate(n = n-1) %>%
spread(word, n)
bigramFeatures <- tweetData %>%
unnest_tokens(bigram, "text", token = "ngrams", n = 2) %>%
right_join(bigram, by = c("bigram" = "bigram")) %>%
count(bigram, bigram) %>%
mutate(n = n-1) %>%
spread(bigram, n)
trigramFeatures <- tweetData %>%
unnest_tokens(trigram, "text", token = "ngrams", n = 3) %>%
right_join(trigram, by = c("trigram" = "trigram")) %>%
count(trigram, trigram) %>%
mutate(n = n-1) %>%
spread(trigram, n)
#Generate positive negative sentiment features
sentences <- tweetData %>% select(text) %>% get_sentences()
sentiments <- cbind(
sentences %>%
sentiment((lexicon::hash_sentiment_huliu)) %>%
select(sentiment) %>%
rename("huliu" = sentiment),
sentences %>%
sentiment(lexicon::hash_sentiment_jockers_rinker) %>%
select(sentiment) %>%
rename("jockers_rinker" = sentiment),
sentences %>%
sentiment(lexicon::hash_sentiment_nrc) %>%
select(sentiment) %>%
rename("nrc" = sentiment),
sentences %>%
sentiment(lexicon::hash_sentiment_senticnet) %>%
select(sentiment) %>%
rename("senticnet" = sentiment),
sentences %>%
sentiment(lexicon::hash_sentiment_sentiword) %>%
select(sentiment) %>%
rename("sentiword" = sentiment),
sentences %>%
sentiment(lexicon::hash_sentiment_slangsd) %>%
select(sentiment) %>%
rename("slangsd" = sentiment),
sentences %>%
sentiment(lexicon::hash_sentiment_socal_google) %>%
select(sentiment) %>%
rename("socal_google" = sentiment))
sentiments <-  sentiments %>%
gather(key = "sentiment", value = "score") %>%
group_by(sentiment) %>%
summarise(score = mean(score)) %>%
spread(key = sentiment, value = score)
#Generates emotion sentiment features such as anger, anticipation, disgust, fear, joy, sadness, surprise, and trust
emotions <- lexicon::nrc_emotions
emotionFeatures <- sentences %>%
unnest_tokens(word, "text") %>%
filter(word %in% emotions$term) %>%
left_join(emotions, by = c("word" = "term")) %>%
select(-word,-element_id, -sentence_id) %>%
summarise_each(funs(sum)) %>%
gather(key = "sentiment", value = "score") %>%
mutate(score = score / sentences %>% unnest_tokens(word, "text") %>% nrow()) %>%
spread(sentiment, score) %>%
rename("anger.emotion" = anger,
"anticipation.emotion" = anticipation,
"digust.emotion" = disgust,
"fear.emotion" = fear,
"joy.emotion" = joy,
"sadness.emotion" = sadness,
"surprise.emotion" = surprise,
"trust.emotion" = trust)
#Combines BOW, Bigram, Trigram, Sentiment, and Emotion features
df <- cbind(bowFeatures, bigramFeatures, trigramFeatures, sentiments, emotionFeatures)
#Reads in models
LogisticRegressionModel <- readRDS("LogisticRegressionModel.rds")
NaiveBayesModel <- readRDS("NaiveBayesModel.rds")
L1Model <- readRDS("L1Model.rds")
L2Model <- readRDS("L2Model.rds")
ElasticNetModel <- readRDS("ElasticNetModel.rds")
MARSModel <- readRDS("MARSModel.rds")
KnnModel <- readRDS("KnnModel.rds")
RandomForestModel <- readRDS("RandomForestModel.rds")
SVMModel <- readRDS("SupportVectorMachineModel.rds")
EnsembleModel <- readRDS("EnsembleModel.rds")
#Generates data for esemble model
ensembleData <- cbind(predict(LogisticRegressionModel, df, type = "prob"),
predict(NaiveBayesModel, df, type = "prob"),
predict(L1Model, df, type = "prob"),
predict(L2Model,df, type = "prob"),
predict(ElasticNetModel, df, type = "prob"),
predict(MARSModel, df, type = "prob"),
predict(KnnModel, df, type = "prob"),
predict(RandomForestModel, df, type = "prob"),
predict(SVMModel, df, type = "prob"))
colnames(ensembleData) <- c("LogisticGryffindor","LogisticHufflepuff","LogisticRavenclaw","LogisticSlytherin",
"NaiveBayesGryffindor","NaiveBayesHufflepuff","NaiveBayesRavenclaw","NaiveBayesSlytherin",
"L1Gryffindor","L1Hufflepuff","L1Ravenclaw","L1Slytherin",
"L2Gryffindor","L2Hufflepuff","L2Ravenclaw","L2Slytherin",
"ElasticNetGryffindor","ElasticNetHufflepuff","ElasticNetRavenclaw","ElasticNetSlytherin",
"MARSGryffindor","MARSHufflepuff","MARSRavenclaw","MARSSlytherin",
"KNNGryffindor","KNNHufflepuff","KNNRavenclaw","KNNSlytherin",
"RandomForestGryffindor","RandomForestHufflepuff","RandomForestRavenclaw","RandomForestSlytherin",
"SVMGryffindor","SVMHufflepuff","SVMRavenclaw","SVMSlytherin")
#Uses ensemble model to make final prediction
HousePrediction <- predict(EnsembleModel, ensembleData, type = "prob")
colnames(HousePrediction) <- c("Gryffindor", "Hufflepuff", "Ravenclaw", "Slytherin")
#Stops parallel computing
stopCluster(cl)
EndTime <- Sys.time()
StartTime - EndTime
#Plots predictions as probabilities/percentage
HousePrediction %>%
gather(key = "House", value = "Percentage") %>%
ggplot(aes(x = House,
y = Percentage,
color = House,
fill = House)) +
geom_col() +
scale_y_continuous(labels = scales::percent) +
ggtitle(paste(userName, "'s House Assignment", sep = "")) +
theme(plot.title = element_text(hjust = .5)) +
theme_economist()
HousePrediction %>%
mutate("Name" = userName) %>%
write.table("SortingHatList.csv",
row.names = FALSE,
col.names = FALSE,
sep = ",",
append = TRUE)
sortedList <- read.csv("SortingHatList.csv")
exampleNames <- sortedList %>%
gather(key = "house", value = "value", -Name) %>%
group_by(Name) %>%
top_n(value, n =1) %>%
select(Name, house) %>%
inner_join(sortedList) %>%
mutate(x = Hufflepuff - Ravenclaw,
y = Gryffindor - Slytherin) %>%
select(Name, x , y, house) %>%
filter(Name %in% c("Book_Harry", "Book_Malfoy" ,userName))
sortedList %>%
gather(key = "house", value = "value", -Name) %>%
group_by(Name) %>%
top_n(value, n =1) %>%
select(Name, house) %>%
inner_join(sortedList) %>%
mutate(x = Hufflepuff - Ravenclaw,
y = Gryffindor - Slytherin) %>%
select(Name, x , y, house) %>%
ggplot(aes(x = x, y = y, label = Name)) +
geom_vline(xintercept = 0, linetype = "dashed", alpha = .5) +
geom_hline(yintercept = 0, linetype = "dashed", alpha = .5) +
geom_point(aes(color = house)) +
geom_text_repel(data = exampleNames,
mapping = aes(x = x, y = y, label = Name),
nudge_x = .1) +
theme_fivethirtyeight() +
theme(aspect.ratio = 1, axis.title = element_text()) +
ylab(expression("More likely Slytherin  " %<->% " More likely Gryffindor")) +
xlab(expression("More likely Ravenclaw  " %<->% " More likely Hufflepuff"))
library(tidyverse)
library(tidytext)
library(rtweet)
library(ggthemes)
library(ggrepel)
rm(list = ls())
get_token()
begin <- Sys.time()
wordVec <- read.csv("wordVec.csv", stringsAsFactors = FALSE)
NaiveModel <- readRDS("FastNaiveModel.rds")
L1Model <- readRDS("FastL1Model.rds")
L2Model <- readRDS("FastL2Model.rds")
ElasticNetModel <- readRDS("FastElasticModel.rds")
MarsModel <- readRDS("FastMarsModel.rds")
KnnModel <- readRDS("FastKnnModel.rds")
RfModel <- readRDS("FastRfModel.rds")
SvmModel <- readRDS("FastSvmModel.rds")
FastModel <- readRDS("FastensembleModel.rds")
userName <- "DPRK_News"
df <- get_timeline(userName, n = 3200)
df <- df %>%
filter(is_retweet == FALSE) %>%
select(text) %>%
mutate(userName = userName)
df$text <- str_trim(gsub('http\\S+\\s*',"", df$text))
df$text <- gsub("(^|[^@\\w])@(\\w{1,15})\\b", "", df$text)
df <- df %>%
filter(!text %in% c(" ", "", "   "))
df <- rbind(df %>% unnest_tokens(word, "text") %>% rename(token = word),
df %>% unnest_tokens(bigram, "text", "ngrams", n = 2) %>% rename(token = bigram),
df %>% unnest_tokens(trigram, "text", "ngrams", n = 3) %>% rename(token = trigram))
df <- df %>%
filter(token %in% wordVec$value) %>%
select(token) %>%
arrange(token) %>%
right_join(wordVec, by = c("token" = "value")) %>%
count(token, token) %>%
mutate(n = n-1,
token = gsub(" ", ".", token)) %>%
spread(key = `token`, value = `n`, fill = 0, drop = FALSE)
modelData <- read.csv("modelData.csv")
modelData$Class <- NULL
colnames(df) <- modelData %>% colnames()
modelData <- cbind(predict(NaiveModel, df, type = "prob") %>%
rename(., "NaiveGryffindor" = Gryffindor, "NaiveHufflepuff" = Hufflepuff, "NaiveRavenclaw" = Ravenclaw, "NaiveSlytherin" = Slytherin),
predict(L1Model, df, type = "prob") %>%
rename(., "L1Gryffindor" = Gryffindor, "L1Hufflepuff" = Hufflepuff, "L1Ravenclaw" = Ravenclaw, "L1Slytherin" = Slytherin),
predict(L2Model, df, type = "prob") %>%
rename(., "L2Gryffindor" = Gryffindor, "L2Hufflepuff" = Hufflepuff, "L2Ravenclaw" = Ravenclaw, "L2Slytherin" = Slytherin),
predict(ElasticNetModel, df, type = "prob") %>%
rename(., "ElasticGryffindor" = Gryffindor, "ElasticHufflepuff" = Hufflepuff, "ElasticRavenclaw" = Ravenclaw, "ElasticSlytherin" = Slytherin),
predict(MarsModel, df, type = "prob") %>%
rename(., "MarsGryffindor" = Gryffindor, "MarsHufflepuff" = Hufflepuff, "MarsRavenclaw" = Ravenclaw, "MarsSlytherin" = Slytherin),
predict(KnnModel, df, type = "prob") %>%
rename(., "KnnGryffindor" = Gryffindor, "KnnHufflepuff" = Hufflepuff, "KnnRavenclaw" = Ravenclaw, "KnnSlytherin" = Slytherin),
predict(RfModel, df, type = "prob") %>%
rename(., "RfGryffindor" = Gryffindor, "RfHufflepuff" = Hufflepuff, "RfRavenclaw" = Ravenclaw, "RfSlytherin" = Slytherin),
predict(SvmModel, df, type = "prob") %>%
rename(., "SvmGryffindor" = Gryffindor, "SvmHufflepuff" = Hufflepuff, "SvmRavenclaw" = Ravenclaw, "Svmlytherin" = Slytherin))
results <- predict(FastModel, modelData, type = "prob") %>% as.data.frame()
results %>%
gather(key = "house", value = "probability") %>%
ggplot(aes(x = house, y = probability, fill = house)) +
geom_col() +
theme_economist()
results %>%
cbind(userName) %>%
write.table("sortedlist.csv",
row.names = FALSE,
col.names = FALSE,
sep = ",",
append = TRUE)
sortedList <- read.csv("sortedlist.csv")
defaultNameExmples <- sortedList %>%
filter(character %in% c(userName, "Book_Harry", "Book_Malfoy")) %>%
mutate(x = Hufflepuff - Ravenclaw,
y = Gryffindor - Slytherin) %>%
select(character, x, y) %>%
inner_join(sortedList %>% gather(key = "house", value = "value", -character) %>%
group_by(character) %>%
top_n(value, n = 1) %>%
select(-value), by = c("character"= "character")) %>% as.data.frame()
sortedList %>%
mutate(x = Hufflepuff - Ravenclaw,
y = Gryffindor - Slytherin) %>%
select(character, x, y) %>%
inner_join(sortedList %>% gather(key = "house", value = "value", -character) %>%
group_by(character) %>%
top_n(value, n = 1) %>%
select(-value), by = c("character"= "character")) %>%
ggplot(aes(x = x, y= y, color = house)) +
geom_jitter(shape = 21, alpha = .4,size = 2, width = .15, height = .15, color = "black", aes(fill = house)) +
geom_text_repel(data = defaultNameExmples,
aes(x = x, y = y, label = character),
nudge_x = .5, color = "black") +
geom_vline(xintercept = 0, linetype = "dashed", alpha = .5) +
geom_hline(yintercept = 0, linetype = "dashed", alpha = .5) +
theme(aspect.ratio = 1, axis.title = element_text()) +
ylab(expression("More likely Slytherin  " %<->% " More likely Gryffindor")) +
xlab(expression("More likely Ravenclaw  " %<->% " More likely Hufflepuff")) +
scale_color_manual(values = c("#B31A1A","#FFDB6D","#3B0DA1","#12B33F")) +
scale_fill_manual(values = c("#B31A1A","#FFDB6D","#3B0DA1","#12B33F"))
end <- Sys.time()
begin-end
