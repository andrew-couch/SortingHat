unnest_tokens(word, "text") %>%
filter(!word %in% nameList$value,
!str_detect(word, pattern = "[[:digit:]]"),
!str_detect(word, pattern = "[[:punct:]]"),
!str_detect(word, pattern = "(.)\\1{2,}"),
!str_detect(word, pattern = "\\b(.)\\b"),) %>%
anti_join(stop_words) %>%
count(house, word, sort = TRUE) %>%
bind_tf_idf(word, house, n) %>%
group_by(house) %>%
filter(tf_idf >= mean(tf_idf)) %>%
top_n(tf_idf, n = 100) %>%
pull(word) %>% unique() %>% length()
df %>%
filter(house != "No Entry") %>%
get_sentences() %>%
unnest_tokens(word, "text") %>%
filter(!word %in% nameList$value,
!str_detect(word, pattern = "[[:digit:]]"),
!str_detect(word, pattern = "[[:punct:]]"),
!str_detect(word, pattern = "(.)\\1{2,}"),
!str_detect(word, pattern = "\\b(.)\\b"),) %>%
anti_join(stop_words) %>%
count(house, word, sort = TRUE) %>%
bind_tf_idf(word, house, n) %>%
group_by(house) %>%
filter(tf_idf >= mean(tf_idf)) %>%
top_n(tf_idf, n = 100) %>%
pull(word) %>%
unique() %>% length()
df %>%
filter(house != "No Entry") %>%
get_sentences() %>%
unnest_tokens(word, "text") %>%
filter(!word %in% nameList$value,
!str_detect(word, pattern = "[[:digit:]]"),
!str_detect(word, pattern = "[[:punct:]]"),
!str_detect(word, pattern = "(.)\\1{2,}"),
!str_detect(word, pattern = "\\b(.)\\b"),) %>%
anti_join(stop_words) %>%
count(house, word, sort = TRUE) %>%
bind_tf_idf(word, house, n) %>%
group_by(house) %>%
top_n(tf_idf, n = 100) %>%
pull(word) %>%
unique() %>% length()
df %>%
get_sentences()
df %>%
get_sentences() %>%
get_sentiments(lexicon = c("afinn", "bing", "nrc"))
?get_sentiments
df %>%
get_sentences() %>%
inner_join(get_sentiments(lexicon = c("afinn", "bing", "nrc")))
inner_join(get_sentiments(lexicon = "nrc")
df %>%
get_sentences() %>%
inner_join(get_sentiments(lexicon = "nrc"))
df %>%
get_sentences() %>%
unnest_tokens(word, "text") %>%
anti_join(stop_words) %>%
inner_join(get_sentiments(lexicon = "nrc"))
df %>%
get_sentences() %>%
unnest_tokens(word, "text") %>%
anti_join(stop_words) %>%
inner_join(get_sentiments(lexicon = "bing"))
df %>%
get_sentences() %>%
unnest_tokens(word, "text") %>%
anti_join(stop_words) %>%
inner_join(get_sentiments(lexicon = "bing")) %>%
group_by(book,character, sentiment) %>%
count(sentiment)
df %>%
get_sentences() %>%
unnest_tokens(word, "text") %>%
anti_join(stop_words) %>%
inner_join(get_sentiments(lexicon = "bing")) %>%
group_by(book,character, sentiment) %>%
count(sentiment)
get_sentiments(lexicon = "bing")
df %>%
get_sentences() %>%
unnest_tokens(word, "text") %>%
anti_join(stop_words) %>%
inner_join(get_sentiments(lexicon = "bing")) %>%
group_by(book,character, sentiment) %>%
count(sentiment)
df %>%
get_sentences() %>%
unnest_tokens(word, "text") %>%
anti_join(stop_words) %>%
inner_join(get_sentiments(lexicon = "bing")) %>%
group_by(book,character, sentence_id, sentiment) %>%
count(sentiment)
df %>%
get_sentences() %>%
unnest_tokens(word, "text") %>%
anti_join(stop_words) %>%
inner_join(get_sentiments(lexicon = "bing")) %>%
group_by(book,character, element_id,sentence_id, sentiment) %>%
count(sentiment)
df %>%
get_sentences() %>%
unnest_tokens(word, "text") %>%
anti_join(stop_words) %>%
inner_join(get_sentiments(lexicon = "bing")) %>%
group_by(book,character, element_id,sentence_id, sentiment) %>%
count(sentiment) %>%
spread(sentiment)
df %>%
get_sentences() %>%
unnest_tokens(word, "text") %>%
anti_join(stop_words) %>%
inner_join(get_sentiments(lexicon = "bing")) %>%
group_by(book,character, element_id,sentence_id, sentiment) %>%
count(sentiment) %>%
spread(sentiment, n)
df %>%
get_sentences() %>%
unnest_tokens(word, "text") %>%
anti_join(stop_words) %>%
inner_join(get_sentiments(lexicon = "bing")) %>%
group_by(book,character, element_id,sentence_id, sentiment) %>%
count(sentiment) %>%
spread(sentiment, n, fill = 0)
library(tidyverse)
library(tidytext)
library(harrypotter)
df <- order_of_the_phoenix
df <- order_of_the_phoenix
library(sentimentr)
df <- df %>% get_sentences()
df <- as.data.frame(df)
View(df)
df <- order_of_the_phoenix
df <- as.data.frame(df)
View(df)
df <- df %>% get_sentences()
View(df)
df <- order_of_the_phoenix
df <- as.data.frame(df)
df <- as.data.frame(df)
View(df)
names <- read.csv("namelist.csv")
verbs <- read.csv("wordList.csv")
View(df)
df %>%
get_sentences() %>%
unnest_tokens(bigram, `df`, token = "ngrams", n = 2) %>%
separate(bigram, c("word1", "word2"), sep = " ") %>%
filter(word1 %in% names$value & word2 %in% verbs$dialogueVerbs)
sentences
sentence <- df %>% get_sentences()
View(sentence)
sentence %>%
unnest_tokens(bigram, `df`, token = "ngrams", n = 2) %>%
separate(bigram, c("word1", "word2"), sep = " ") %>%
filter(word1 %in% names$value & word2 %in% verbs$dialogueVerbs)
sentence %>%
unnest_tokens(bigram, `df`, token = "ngrams", n = 2) %>%
separate(bigram, c("word1", "word2"), sep = " ") %>%
filter(word1 %in% names$value & word2 %in% verbs$dialogueVerbs) %>%
select(sentence_id)
sentence %>%
unnest_tokens(bigram, `df`, token = "ngrams", n = 2) %>%
separate(bigram, c("word1", "word2"), sep = " ") %>%
filter(word1 %in% names$value & word2 %in% verbs$dialogueVerbs) %>%
select(sentence_id) %>%
unique()
sentence %>%
unnest_tokens(bigram, `df`, token = "ngrams", n = 2) %>%
separate(bigram, c("word1", "word2"), sep = " ") %>%
filter((word1 %in% names$value & word2 %in% verbs$dialogueVerbs) | word1 %in% verbs$dialogueVerbs & word2 %in% names$value) %>%
select(sentence_id) %>%
unique()
sentence %>%
unnest_tokens(bigram, `df`, token = "ngrams", n = 2) %>%
separate(bigram, c("word1", "word2"), sep = " ") %>%
filter((word1 %in% names$value & word2 %in% verbs$dialogueVerbs) | word1 %in% verbs$dialogueVerbs & word2 %in% names$value) %>%
select(sentence_id) %>%
unique() %>%
arrange()
sentence %>%
unnest_tokens(bigram, `df`, token = "ngrams", n = 2) %>%
separate(bigram, c("word1", "word2"), sep = " ") %>%
filter((word1 %in% names$value & word2 %in% verbs$dialogueVerbs) | word1 %in% verbs$dialogueVerbs & word2 %in% names$value) %>%
select(sentence_id) %>%
unique() %>%
arrange(sentence_id)
ids <- sentence %>%
unnest_tokens(bigram, `df`, token = "ngrams", n = 2) %>%
separate(bigram, c("word1", "word2"), sep = " ") %>%
filter((word1 %in% names$value & word2 %in% verbs$dialogueVerbs) | word1 %in% verbs$dialogueVerbs & word2 %in% names$value) %>%
select(sentence_id) %>%
unique() %>%
arrange(sentence_id)
sentence
sentence %>%
filter(sentence_id %in% ids)
sentence %>%
filter(sentence_id %in% ids)
View(ids)
sentence %>%
filter(sentence_id %in% ids$sentence_id)
sentence %>%
filter(sentence_id %in% ids$sentence_id) %>% nrow()
View(ids)
sentence %>% select(sentence_id)
sentence %>% select(sentence_id) %>% summary()
filter(sentence$sentence_id %in% ids$sentence_id)
sentence %>% filter(sentence_id %in% ids$sentence_id)
sentence %>% filter(sentence_id %in% ids$sentence_id) %>% nrow()
View(ids)
View(df)
View(sentence)
View(ids)
ids <- sentence %>%
unnest_tokens(bigram, `df`, token = "ngrams", n = 2) %>%
separate(bigram, c("word1", "word2"), sep = " ") %>%
filter(word1 %in% names$value & word2 %in% verbs$dialogueVerbs) %>%
select(sentence_id)
View(ids)
ids <- sentence %>%
unnest_tokens(bigram, `df`, token = "ngrams", n = 2) %>%
separate(bigram, c("word1", "word2"), sep = " ") %>%
filter(word1 %in% names$value & word2 %in% verbs$dialogueVerbs) %>%
select(sentence_id) %>% unqiue(sentence_id)
ids <- sentence %>%
unnest_tokens(bigram, `df`, token = "ngrams", n = 2) %>%
separate(bigram, c("word1", "word2"), sep = " ") %>%
filter(word1 %in% names$value & word2 %in% verbs$dialogueVerbs) %>%
select(sentence_id) %>%
unique(sentence_id)
ids <- sentence %>%
unnest_tokens(bigram, `df`, token = "ngrams", n = 2) %>%
separate(bigram, c("word1", "word2"), sep = " ") %>%
filter(word1 %in% names$value & word2 %in% verbs$dialogueVerbs) %>%
select(sentence_id) %>%
unique(sentence_id)
sentence %>%
unnest_tokens(bigram, `df`, token = "ngrams", n = 2) %>%
separate(bigram, c("word1", "word2"), sep = " ") %>%
filter(word1 %in% names$value & word2 %in% verbs$dialogueVerbs) %>%
select(sentence_id)
sentence %>%
unnest_tokens(bigram, `df`, token = "ngrams", n = 2) %>%
separate(bigram, c("word1", "word2"), sep = " ") %>%
filter(word1 %in% names$value & word2 %in% verbs$dialogueVerbs) %>%
select(sentence_id) %>%
unique()
sentence %>%
unnest_tokens(bigram, `df`, token = "ngrams", n = 2) %>%
separate(bigram, c("word1", "word2"), sep = " ") %>%
filter(word1 %in% names$value & word2 %in% verbs$dialogueVerbs) %>%
select(sentence_id) %>%
unique() %>%
arrange(sentence_id)
ids <- sentence %>%
unnest_tokens(bigram, `df`, token = "ngrams", n = 2) %>%
separate(bigram, c("word1", "word2"), sep = " ") %>%
filter(word1 %in% names$value & word2 %in% verbs$dialogueVerbs) %>%
select(sentence_id) %>%
unique() %>%
arrange(sentence_id)
sentence %>% filter(sentence_id %in% ids$sentence_id)
View(ids)
ids <- sentence %>%
unnest_tokens(bigram, `df`, token = "ngrams", n = 2) %>%
separate(bigram, c("word1", "word2"), sep = " ")
ids <- sentence %>%
unnest_tokens(bigram, `df`, token = "ngrams", n = 2) %>%
separate(bigram, c("word1", "word2"), sep = " ") %>%
filter(word1 %in% names$value & word2 %in% verbs$dialogueVerbs) %>%
select(sentence_id) %>%
unique() %>%
arrange(sentence_id)
sentence %>%
unnest_tokens(bigram, `df`, token = "ngrams", n = 2) %>%
separate(bigram, c("word1", "word2"), sep = " ")
sentence %>%
unnest_tokens(bigram, `df`, token = "ngrams", n = 2) %>%
separate(bigram, c("word1", "word2"), sep = " ") %>%
filter(word1 %in% names)
sentence %>%
unnest_tokens(bigram, `df`, token = "ngrams", n = 2) %>%
separate(bigram, c("word1", "word2"), sep = " ") %>%
filter(word1 %in% names$value)
View(names)
View(names)
names %>% str
names %>% str()
names <- read.csv("namelist.csv", stringsAsFactors = FALSE)
verbs <- read.csv("wordList.csv", stringsAsFactors = FALSE)
sentence %>%
unnest_tokens(bigram, `df`, token = "ngrams", n = 2) %>%
separate(bigram, c("word1", "word2"), sep = " ") %>%
filter(word1 %in% names$value)
View(names)
names %>% unique()
names %>% unique() %>% arrange()
View(names)
names %>% unique() %>% arrange(value)
names <- names %>% unique() %>% arrange(value)
View(names)
sentence %>%
unnest_tokens(bigram, `df`, token = "ngrams", n = 2) %>%
separate(bigram, c("word1", "word2"), sep = " ") %>%
filter(word1 %in% names$value && word2 %in% verbs$dialogueVerbs)
sentence %>%
unnest_tokens(bigram, `df`, token = "ngrams", n = 2) %>%
separate(bigram, c("word1", "word2"), sep = " ") %>%
filter(word1 %in% names$value & word2 %in% verbs$dialogueVerbs)
sentence %>%
unnest_tokens(bigram, `df`, token = "ngrams", n = 2) %>%
separate(bigram, c("word1", "word2"), sep = " ") %>%
filter(word1 %in% names$value & word2 %in% verbs$dialogueVerbs) %>%
select(sentence_id) %>%
unique() %>%
arrange(sentence_id)
sentence %>%
unnest_tokens(bigram, `df`, token = "ngrams", n = 2) %>%
separate(bigram, c("word1", "word2"), sep = " ") %>%
filter(word1 %in% names$value & word2 %in% verbs$dialogueVerbs) %>%
arrange(sentence_id)
View(df)
View(sentence)
sentence[1]
sentence %>%
unnest_tokens(bigram, `df`, token = "ngrams", n = 2) %>%
separate(bigram, c("word1", "word2"), sep = " ") %>%
filter(word1 %in% names$value & word2 %in% verbs$dialogueVerbs) %>%
select(element_id, sentence_id) %>%
arrange(element_id, sentence_id)
ids <- sentence %>%
unnest_tokens(bigram, `df`, token = "ngrams", n = 2) %>%
separate(bigram, c("word1", "word2"), sep = " ") %>%
filter(word1 %in% names$value & word2 %in% verbs$dialogueVerbs) %>%
select(element_id, sentence_id) %>%
arrange(element_id, sentence_id)
sentence %>% filter(element_id %in% ids$element_id & sentence_id %in% ids$sentence_id)
sentence %>% filter(element_id %in% ids$element_id & sentence_id %in% ids$sentence_id) %>%
left_join(ids, by = c("element_id" = "element_id", "sentence_id" = "sentence_id"))
sentence %>% filter(element_id %in% ids$element_id & sentence_id %in% ids$sentence_id) %>%
inner_join(ids, by = c("element_id" = "element_id", "sentence_id" = "sentence_id")) %>%
sentence %>% filter(element_id %in% ids$element_id & sentence_id %in% ids$sentence_id) %>%
inner_join(ids, by = c("element_id" = "element_id", "sentence_id" = "sentence_id"))
sentence %>%
filter(element_id %in% ids$element_id & sentence_id %in% ids$sentence_id) %>%
inner_join(ids, by = c("element_id" = "element_id", "sentence_id" = "sentence_id"))
order <- sentence %>%
filter(element_id %in% ids$element_id & sentence_id %in% ids$sentence_id) %>%
inner_join(ids, by = c("element_id" = "element_id", "sentence_id" = "sentence_id"))
order
View(order)
View(ids)
ids <- sentence %>%
unnest_tokens(bigram, `df`, token = "ngrams", n = 2) %>%
separate(bigram, c("word1", "word2"), sep = " ") %>%
filter(word1 %in% names$value & word2 %in% verbs$dialogueVerbs)
order <- sentence %>%
filter(element_id %in% ids$element_id & sentence_id %in% ids$sentence_id) %>%
inner_join(ids, by = c("element_id" = "element_id", "sentence_id" = "sentence_id"))
View(order)
order <- sentence %>%
filter(element_id %in% ids$element_id & sentence_id %in% ids$sentence_id) %>%
inner_join(ids, by = c("element_id" = "element_id", "sentence_id" = "sentence_id")) %>%
gather()
order <- sentence %>%
filter(element_id %in% ids$element_id & sentence_id %in% ids$sentence_id) %>%
inner_join(ids, by = c("element_id" = "element_id", "sentence_id" = "sentence_id"))
View(order)
order <- sentence %>%
filter(element_id %in% ids$element_id & sentence_id %in% ids$sentence_id) %>%
inner_join(ids, by = c("element_id" = "element_id", "sentence_id" = "sentence_id")) %>%
gather(key = "character", word1, word2)
order <- sentence %>%
filter(element_id %in% ids$element_id & sentence_id %in% ids$sentence_id) %>%
inner_join(ids, by = c("element_id" = "element_id", "sentence_id" = "sentence_id")) %>%
gather(key = "character", -df, -element_id, -sentence_id)
order <- sentence %>%
filter(element_id %in% ids$element_id & sentence_id %in% ids$sentence_id) %>%
inner_join(ids, by = c("element_id" = "element_id", "sentence_id" = "sentence_id")) %>%
gather(key = "character",value = "value", -df, -element_id, -sentence_id)
order <- sentence %>%
filter(element_id %in% ids$element_id & sentence_id %in% ids$sentence_id) %>%
inner_join(ids, by = c("element_id" = "element_id", "sentence_id" = "sentence_id")) %>%
gather(key = "character",value = "value", -df, -element_id, -sentence_id) %>%
select(-character) %>%
filter(value %in% names$value)
df %>% get_sentences() %>%
filter(str_detect(text, '\\''') == TRUE)
df %>% get_sentences() %>%
filter(str_detect(text, '\'') == TRUE)
sentence
sentence %>%
filter(str_detect(df, '\'') == TRUE)
sentence %>%
filter(str_detect(df, '\'') == TRUE) %>%
unnest_tokens(bigram, `df`, token = "ngrams", n = 2) %>%
separate(bigram, c("word1", "word2"), sep = " ") %>%
filter(word1 %in% names$value & word2 %in% verbs$dialogueVerbs)
sentence %>%
filter(str_detect(df, '\'') == TRUE) %>%
unnest_tokens(bigram, `df`, token = "ngrams", n = 2) %>%
separate(bigram, c("word1", "word2"), sep = " ") %>%
filter(word1 %in% names$value & word2 %in% verbs$dialogueVerbs)
sentence %>%
filter(str_detect(df, '\'') == TRUE) %>%
unnest_tokens(bigram, `df`, token = "ngrams", n = 2) %>%
separate(bigram, c("word1", "word2"), sep = " ") %>%
filter(word1 %in% names$value & word2 %in% verbs$dialogueVerbs) %>% nrow()
sentence %>%
filter(str_detect(df, '\'') == TRUE) %>%
unnest_tokens(bigram, `df`, token = "ngrams", n = 2) %>%
separate(bigram, c("word1", "word2"), sep = " ") %>%
filter(word1 %in% names$value & word2 %in% verbs$dialogueVerbs)
sentences <- sentence %>%
filter(str_detect(df, '\'') == TRUE) %>%
unnest_tokens(bigram, `df`, token = "ngrams", n = 2) %>%
separate(bigram, c("word1", "word2"), sep = " ") %>%
filter(word1 %in% names$value & word2 %in% verbs$dialogueVerbs)
View(order)
View(verbs)
View(sentence)
View(order)
View(sentences)
sentences <- sentence %>%
filter(str_detect(df, '\'') == TRUE) %>%
unnest_tokens(bigram, `df`, token = "ngrams", n = 2) %>%
separate(bigram, c("word1", "word2"), sep = " ") %>%
filter(word1 %in% names$value & word2 %in% verbs$dialogueVerbs |
word1 %in% verbs$dialogueVerbs & word2 %in% names$value)
sentences <- sentence %>%
filter(str_detect(df, '\'') == TRUE) %>%
unnest_tokens(bigram, `df`, token = "ngrams", n = 2) %>%
separate(bigram, c("word1", "word2"), sep = " ") %>%
filter(word1 %in% names$value & word2 %in% verbs$dialogueVerbs |
word1 %in% verbs$dialogueVerbs & word2 %in% names$value) %>%
gather(key = "chracter", value = "value", -element_id, -sentence_id)
sentences <- sentence %>%
filter(str_detect(df, '\'') == TRUE) %>%
unnest_tokens(bigram, `df`, token = "ngrams", n = 2) %>%
separate(bigram, c("word1", "word2"), sep = " ") %>%
filter(word1 %in% names$value & word2 %in% verbs$dialogueVerbs |
word1 %in% verbs$dialogueVerbs & word2 %in% names$value) %>%
gather(key = "chracter", value = "value", -element_id, -sentence_id) %>%
select(-character) %>%
filter(value %in% names$value)
sentences <- sentence %>%
filter(str_detect(df, '\'') == TRUE) %>%
unnest_tokens(bigram, `df`, token = "ngrams", n = 2) %>%
separate(bigram, c("word1", "word2"), sep = " ") %>%
filter(word1 %in% names$value & word2 %in% verbs$dialogueVerbs |
word1 %in% verbs$dialogueVerbs & word2 %in% names$value) %>%
gather(key = "chracter", value = "value", -element_id, -sentence_id) %>%
select(-character) %>%
filter(value %in% names$value)
sentences <- sentence %>%
filter(str_detect(df, '\'') == TRUE) %>%
unnest_tokens(bigram, `df`, token = "ngrams", n = 2) %>%
separate(bigram, c("word1", "word2"), sep = " ") %>%
filter(word1 %in% names$value & word2 %in% verbs$dialogueVerbs |
word1 %in% verbs$dialogueVerbs & word2 %in% names$value) %>%
gather(key = "chracter", value = "value", -element_id, -sentence_id) %>%
select(-chracter) %>%
filter(value %in% names$value)
sentences <- rbind(sentences, order)
order %>% select(element_id, sentence_id, value) %>% rbind(sentences)
sentences <- order %>% select(element_id, sentence_id, value) %>% rbind(sentences)
sentences %>% unique()
sentences nrow()
sentences %>% nrow()
sentences %>% unique() %>% nrow()
sentences <- sentence %>%
filter(str_detect(df, '\'') == TRUE) %>%
unnest_tokens(bigram, `df`, token = "ngrams", n = 2) %>%
separate(bigram, c("word1", "word2"), sep = " ") %>%
filter(word1 %in% names$value & word2 %in% verbs$dialogueVerbs |
word1 %in% verbs$dialogueVerbs & word2 %in% names$value) %>%
gather(key = "chracter", value = "value", -element_id, -sentence_id) %>%
select(-chracter) %>%
filter(value %in% names$value)
sentences %>% inner_join(sentence, by = c("element_id" = "element_id", "sentence_id" = "sentence_id"))
sentences <- sentences %>% inner_join(sentence, by = c("element_id" = "element_id", "sentence_id" = "sentence_id"))
View(names)
names %>% filter(value %in% stop_words$word)
names %>% filter(!value %in% stop_words$word)
names <- names %>% filter(!value %in% stop_words$word)
sentences <- sentence %>%
filter(str_detect(df, '\'') == TRUE) %>%
unnest_tokens(bigram, `df`, token = "ngrams", n = 2) %>%
separate(bigram, c("word1", "word2"), sep = " ") %>%
filter(word1 %in% names$value & word2 %in% verbs$dialogueVerbs |
word1 %in% verbs$dialogueVerbs & word2 %in% names$value) %>%
gather(key = "chracter", value = "value", -element_id, -sentence_id) %>%
select(-chracter) %>%
filter(value %in% names$value)
sentences <- sentences %>% inner_join(sentence, by = c("element_id" = "element_id", "sentence_id" = "sentence_id"))
View(sentences)
df %>% write.csv(sentences, "sentence.csv", row.names = FALSE)
write.csv(sentences, "sentence.csv", row.names = FALSE)
nameList <- read.csv("namelist.csv")
nameList %>% unique() %>% filter(!values %in% stop_words)
View(nameList)
nameList %>% unique() %>% filter(!value %in% stop_words)
nameList %>% unique() %>% filter(!value %in% stop_words) %>% arrange(value)
namelist <- nameList %>% unique() %>% filter(!value %in% stop_words) %>% arrange(value)
write.csv(namelist, "namelist.csv", row.names = FALSE)
