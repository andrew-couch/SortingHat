"sadness.emotion" = sadness,
"surprise.emotion" = surprise,
"trust.emotion" = trust)
emotionFeatures
cbind(bowFeatures, bigramFeatures, trigramFeatures, sentiments, emotionFeatures)
cbind(bowFeatures, bigramFeatures, trigramFeatures, sentiments, emotionFeatures) %>% ncol()
df <- cbind(bowFeatures, bigramFeatures, trigramFeatures, sentiments, emotionFeatures) %>% ncol()
df <- cbind(bowFeatures, bigramFeatures, trigramFeatures, sentiments, emotionFeatures)
readRDS("harrypotter.rds")
harrypotter <- readRDS("harrypotter.rds")
df %>% colnames()
harrypotter %>% colnames()
readRDS("NaiveBayesModel")
model <- readRDS("NaiveBayesModel.rds")
predict(model, df)
df %>% colnames()
harrypotter %>% colnames()
dfNames <- df %>% colnames()
hpNames <- harrypotter %>% colnames()
dfNames <- df %>% colnames() %>% as.data.frame()
hpNames <- harrypotter %>% colnames() %>% as.data.frame()
View(dfNames)
dfNames <- df %>% colnames() %>% as.data.frame() %>% rename("name" = .)
dfNames <- df %>% colnames() %>% as.data.frame() %>% rename(.,"name" = .)
hpNames <- harrypotter %>% colnames() %>% as.data.frame() %>% rename(., "name" = .)
anti_join(dfNames, hpNames)
hpNames %>% filter(name %in% c("aside"))
dfNames %>% filter(name == "aside")
bow
library(tidyverse)
library(tidytext)
library(sentimentr)
df <- read.csv("harrypotter.csv", stringsAsFactors = FALSE)
df <- df %>% filter(house != "No Entry")
nameList <- read.csv("namelist.csv")
#writes bag of words list
bow <- df %>%
filter(house != "No Entry") %>%
get_sentences() %>%
unnest_tokens(word, "text") %>%
filter(!word %in% nameList$value,
!str_detect(word, pattern = "[[:digit:]]"),
!str_detect(word, pattern = "[[:punct:]]"),
!str_detect(word, pattern = "(.)\\1{2,}"),
!str_detect(word, pattern = "\\b(.)\\b")) %>%
count(house, word, sort = TRUE) %>%
bind_tf_idf(word, house, n) %>%
group_by(house) %>%
top_n(tf_idf, n = 100) %>%
pull(word) %>%
unique() %>%
sort()
#generates bag of word features
bowFeatures <- df %>%
unnest_tokens(word, "text") %>%
anti_join(stop_words) %>%
filter(word %in%  bow) %>%
count(character, word) %>%
spread(word, n) %>%
map_df(replace_na, 0)
#writes bigram list
bigrams <- df %>%
unnest_tokens(bigram, "text", token = "ngrams", n = 2) %>%
separate(bigram, c("word1", "word2"), sep = " ") %>%
filter(!word1 %in% nameList$value,
!word2 %in% nameList$value) %>%
unite("bigram", c(word1, word2), sep = " ") %>%
count(house, bigram, sort = TRUE) %>%
bind_tf_idf(bigram, house ,n) %>%
group_by(house) %>%
top_n(tf_idf, n = 100) %>%
pull(bigram) %>%
unique() %>%
sort()
#generates bigram features
bigramFeatures <- df %>%
unnest_tokens(bigram, "text", token = "ngrams", n = 2) %>%
filter(bigram %in% bigrams) %>%
count(character, bigram) %>%
spread(bigram, n) %>%
map_df(replace_na, 0)
#writes trigram list
trigrams <- df %>%
unnest_tokens(trigram, "text", token = "ngrams", n = 3) %>%
separate(trigram, c("word1","word2","word3"), sep = " ") %>%
filter(!word1 %in% nameList$value) %>%
filter(!word2 %in% nameList$value) %>%
filter(!word3 %in% nameList$value) %>%
unite("trigram", c(word1, word2, word3), sep = " ") %>%
count(house, trigram) %>%
bind_tf_idf(house, trigram, n) %>%
group_by(house) %>%
top_n(n, n = 25) %>%
pull(trigram) %>%
unique() %>%
sort()
#generates trigram features
trigramFeatures <- df %>%
unnest_tokens(trigram, "text", token = "ngrams", n = 3) %>%
filter(trigram %in% trigrams) %>%
count(character, trigram) %>%
spread(trigram, n) %>%
map_df(replace_na, 0)
#sentiment lexicon engineering
sentiments <- cbind(sentences %>%
sentiment(lexicon::hash_sentiment_huliu) %>%
select(sentiment) %>%
rename("huliu" = sentiment),sentences %>%
sentiment(lexicon::hash_sentiment_jockers_rinker) %>%
select(sentiment) %>%
rename("jockers_rinker" = sentiment),
sentences %>%
(lexicon::hash_sentiment_nrc) %>%
select(sentiment) %>%
sentiment(lexicon::hash_nrc_emotions) %>%
rename("nrc" = sentiment),
sentences %>%
sentiment(lexicon::hash_sentiment_senticnet) %>%
select(sentiment) %>%
rename("senticnet" = sentiment),
sentences %>%
sentiment(lexicon::hash_sentiment_sentiword) %>%
select(sentiment) %>%
rename("sentiword" = sentiment),
sentences %>%
sentiment(lexicon::hash_sentiment_slangsd) %>%
select(sentiment) %>%
rename("slangsd" = sentiment),
sentences %>%
sentiment(lexicon::hash_sentiment_socal_google) %>%
select(sentiment) %>%
rename("socal_google" = sentiment))
#Finds average sentiment for each character
sentiments <-  sentiments %>%
select(-text) %>%
gather(key = "sentiment", value = "score", -character) %>%
group_by(character, sentiment) %>%
summarise(score = mean(score)) %>% #Finds mean sentiment by sentences
spread(key = sentiment, value = score)
#Generates emotion features
emotions <- lexicon::nrc_emotions
emotionFeatures <- df %>%
get_sentences() %>%
unnest_tokens(word, `text`) %>%
filter(word %in% emotions$term) %>%
left_join(emotions, by = c("word" = "term")) %>%
select(-word) %>%
select(character, anger, anticipation, disgust, fear, joy, sadness, surprise, trust) %>%
group_by(character) %>%
summarise_each(funs(sum)) %>%
left_join(df %>%
unnest_tokens(word, "text") %>%
group_by(character) %>%
count(character, character),
by = c("character" = "character")) %>%
gather(key = "sentiment", value = "score", -character, -n) %>%
mutate(score = score/n) %>% #Averages the sentiment by word count
select(-n) %>%
spread(sentiment, score) %>%
rename("anger.emotion" = anger,
"anticipation.emotion" = anticipation,
"digust.emotion" = disgust,
"fear.emotion" = fear,
"joy.emotion" = joy,
"sadness.emotion" = sadness,
"surprise.emotion" = surprise,
"trust.emotion" = trust)
#Creates final df for modeling
harrypotter <- df %>%
select(house,character) %>%
rename("TargetHouse" = house) %>%
unique() %>%
arrange() %>%
left_join(bowFeatures) %>%
left_join(bigramFeatures) %>%
left_join(trigramFeatures) %>%
left_join(sentiments) %>%
left_join(emotionFeatures) %>%
map_df(replace_na, 0)
#saveRDS(harrypotter, "harrypotter.rds")
sentiments <- cbind(sentences %>%
sentiment(lexicon::hash_sentiment_huliu) %>%
select(sentiment) %>%
rename("huliu" = sentiment),
sentences %>%
sentiment(lexicon::hash_sentiment_jockers_rinker) %>%
select(sentiment) %>%
rename("jockers_rinker" = sentiment),
sentences %>%
(lexicon::hash_sentiment_nrc) %>%
select(sentiment) %>%
sentiment(lexicon::hash_nrc_emotions) %>%
rename("nrc" = sentiment),
sentences %>%
sentiment(lexicon::hash_sentiment_senticnet) %>%
select(sentiment) %>%
rename("senticnet" = sentiment),
sentences %>%
sentiment(lexicon::hash_sentiment_sentiword) %>%
select(sentiment) %>%
rename("sentiword" = sentiment),
sentences %>%
sentiment(lexicon::hash_sentiment_slangsd) %>%
select(sentiment) %>%
rename("slangsd" = sentiment),
sentences %>%
sentiment(lexicon::hash_sentiment_socal_google) %>%
select(sentiment) %>%
rename("socal_google" = sentiment))
#sentiment lexicon engineering
sentences
#sentiment lexicon engineering
df %>% get_sentences()
sentences <- df %>% get_sentences() %>% select(text)
sentiments <- cbind(sentences %>%
sentiment(lexicon::hash_sentiment_huliu) %>%
select(sentiment) %>%
rename("huliu" = sentiment),
sentences %>%
sentiment(lexicon::hash_sentiment_jockers_rinker) %>%
select(sentiment) %>%
rename("jockers_rinker" = sentiment),
sentences %>%
(lexicon::hash_sentiment_nrc) %>%
select(sentiment) %>%
sentiment(lexicon::hash_nrc_emotions) %>%
rename("nrc" = sentiment),
sentences %>%
sentiment(lexicon::hash_sentiment_senticnet) %>%
select(sentiment) %>%
rename("senticnet" = sentiment),
sentences %>%
sentiment(lexicon::hash_sentiment_sentiword) %>%
select(sentiment) %>%
rename("sentiword" = sentiment),
sentences %>%
sentiment(lexicon::hash_sentiment_slangsd) %>%
select(sentiment) %>%
rename("slangsd" = sentiment),
sentences %>%
sentiment(lexicon::hash_sentiment_socal_google) %>%
select(sentiment) %>%
rename("socal_google" = sentiment))
sentiments <- cbind(sentences %>%
sentiment(lexicon::hash_sentiment_huliu) %>%
select(sentiment) %>%
rename("huliu" = sentiment),
sentences %>%
sentiment(lexicon::hash_sentiment_jockers_rinker) %>%
select(sentiment) %>%
rename("jockers_rinker" = sentiment),
sentences %>%
sentiment(lexicon::hash_sentiment_nrc) %>%
select(sentiment) %>%
sentiment(lexicon::hash_nrc_emotions) %>%
rename("nrc" = sentiment),
sentences %>%
sentiment(lexicon::hash_sentiment_senticnet) %>%
select(sentiment) %>%
rename("senticnet" = sentiment),
sentences %>%
sentiment(lexicon::hash_sentiment_sentiword) %>%
select(sentiment) %>%
rename("sentiword" = sentiment),
sentences %>%
sentiment(lexicon::hash_sentiment_slangsd) %>%
select(sentiment) %>%
rename("slangsd" = sentiment),
sentences %>%
sentiment(lexicon::hash_sentiment_socal_google) %>%
select(sentiment) %>%
rename("socal_google" = sentiment))
sentences <- df %>% get_sentences() %>% select(text)
sentiments <- cbind(sentences %>%
sentiment(lexicon::hash_sentiment_huliu) %>%
select(sentiment) %>%
rename("huliu" = sentiment),
sentences %>%
sentiment(lexicon::hash_sentiment_jockers_rinker) %>%
select(sentiment) %>%
rename("jockers_rinker" = sentiment),
sentences %>%
sentiment(lexicon::hash_sentiment_nrc) %>%
select(sentiment) %>%
rename("nrc" = sentiment),
sentences %>%
sentiment(lexicon::hash_sentiment_senticnet) %>%
select(sentiment) %>%
rename("senticnet" = sentiment),
sentences %>%
sentiment(lexicon::hash_sentiment_sentiword) %>%
select(sentiment) %>%
rename("sentiword" = sentiment),
sentences %>%
sentiment(lexicon::hash_sentiment_slangsd) %>%
select(sentiment) %>%
rename("slangsd" = sentiment),
sentences %>%
sentiment(lexicon::hash_sentiment_socal_google) %>%
select(sentiment) %>%
rename("socal_google" = sentiment))
#Finds average sentiment for each character
sentiments <-  sentiments %>%
select(-text) %>%
gather(key = "sentiment", value = "score", -character) %>%
group_by(character, sentiment) %>%
summarise(score = mean(score)) %>% #Finds mean sentiment by sentences
spread(key = sentiment, value = score)
#Generates emotion features
emotions <- lexicon::nrc_emotions
emotionFeatures <- df %>%
get_sentences() %>%
unnest_tokens(word, `text`) %>%
filter(word %in% emotions$term) %>%
left_join(emotions, by = c("word" = "term")) %>%
select(-word) %>%
select(character, anger, anticipation, disgust, fear, joy, sadness, surprise, trust) %>%
group_by(character) %>%
summarise_each(funs(sum)) %>%
left_join(df %>%
unnest_tokens(word, "text") %>%
group_by(character) %>%
count(character, character),
by = c("character" = "character")) %>%
gather(key = "sentiment", value = "score", -character, -n) %>%
mutate(score = score/n) %>% #Averages the sentiment by word count
select(-n) %>%
spread(sentiment, score) %>%
rename("anger.emotion" = anger,
"anticipation.emotion" = anticipation,
"digust.emotion" = disgust,
"fear.emotion" = fear,
"joy.emotion" = joy,
"sadness.emotion" = sadness,
"surprise.emotion" = surprise,
"trust.emotion" = trust)
#Creates final df for modeling
harrypotter <- df %>%
select(house,character) %>%
rename("TargetHouse" = house) %>%
unique() %>%
arrange() %>%
left_join(bowFeatures) %>%
left_join(bigramFeatures) %>%
left_join(trigramFeatures) %>%
left_join(sentiments) %>%
left_join(emotionFeatures) %>%
map_df(replace_na, 0)
View(bowFeatures)
library(tidyverse)
library(rtweet)
library(tidytext)
library(sentimentr)
userName <- "_AndrewCouch"
bow <- read.csv("bowlist.csv", header = TRUE,stringsAsFactors = FALSE)
bigram <- read.csv("bigramlist.csv", header = TRUE,stringsAsFactors = FALSE)
trigram <- read.csv("trigramlist.csv", header = TRUE,stringsAsFactors = FALSE)
token <- readRDS("twitter_token.rds")
myTweets <- get_timeline(userName, n = 3200)
tweetData <- myTweets %>%
filter(is_retweet == FALSE) %>%
select(text) %>%
mutate(userName = userName)
tweetData$text <- str_trim(gsub('http\\S+\\s*',"", tweetData$text))
tweetData$text <- gsub("(^|[^@\\w])@(\\w{1,15})\\b", "", tweetData$text)
tweetData <- tweetData %>%
filter(!text %in% c(" ", "", "   "))
bowFeatures <- tweetData %>%
unnest_tokens(word, "text") %>%
right_join(bow, by = c("word" = "bow")) %>%
count(word, word) %>%
mutate(n = n-1) %>%
spread(word, n)
bigramFeatures <- tweetData %>%
unnest_tokens(bigram, "text", token = "ngrams", n = 2) %>%
right_join(bigram, by = c("bigram" = "bigram")) %>%
count(bigram, bigram) %>%
mutate(n = n-1) %>%
spread(bigram, n)
trigramFeatures <- tweetData %>%
unnest_tokens(trigram, "text", token = "ngrams", n = 3) %>%
right_join(trigram, by = c("trigram" = "trigram")) %>%
count(trigram, trigram) %>%
mutate(n = n-1) %>%
spread(trigram, n)
sentences <- tweetData %>% select(text) %>% get_sentences()
sentiments <- cbind(
sentences %>%
sentiment((lexicon::hash_sentiment_huliu)) %>%
select(sentiment) %>%
rename("huliu" = sentiment),
sentences %>%
sentiment(lexicon::hash_sentiment_jockers_rinker) %>%
select(sentiment) %>%
rename("jockers_rinker" = sentiment),
sentences %>%
sentiment(lexicon::hash_sentiment_nrc) %>%
select(sentiment) %>%
rename("nrc" = sentiment),
sentences %>%
sentiment(lexicon::hash_sentiment_senticnet) %>%
select(sentiment) %>%
rename("senticnet" = sentiment),
sentences %>%
sentiment(lexicon::hash_sentiment_sentiword) %>%
select(sentiment) %>%
rename("sentiword" = sentiment),
sentences %>%
sentiment(lexicon::hash_sentiment_slangsd) %>%
select(sentiment) %>%
rename("slangsd" = sentiment),
sentences %>%
sentiment(lexicon::hash_sentiment_socal_google) %>%
select(sentiment) %>%
rename("socal_google" = sentiment))
sentiments <-  sentiments %>%
gather(key = "sentiment", value = "score") %>%
group_by(sentiment) %>%
summarise(score = mean(score)) %>%
spread(key = sentiment, value = score)
emotions <- lexicon::nrc_emotions
emotionFeatures <- sentences %>%
unnest_tokens(word, "text") %>%
filter(word %in% emotions$term) %>%
left_join(emotions, by = c("word" = "term")) %>%
select(-word,-element_id, -sentence_id) %>%
summarise_each(funs(sum)) %>%
gather(key = "sentiment", value = "score") %>%
mutate(score = score / sentences %>% unnest_tokens(word, "text") %>% nrow()) %>%
spread(sentiment, score) %>%
rename("anger.emotion" = anger,
"anticipation.emotion" = anticipation,
"digust.emotion" = disgust,
"fear.emotion" = fear,
"joy.emotion" = joy,
"sadness.emotion" = sadness,
"surprise.emotion" = surprise,
"trust.emotion" = trust)
df <- cbind(bowFeatures, bigramFeatures, trigramFeatures, sentiments, emotionFeatures)
harrypotter <- readRDS("harrypotter.rds")
twitterNames <- df %>% colnames()
harryNames <- df %>% colnames()
twitterNames <- df %>% colnames() %>% as.data.frame() %>% rename(., "name" = .)
harryNames <- df %>% colnames() %>% as.data.frame() %>% rename(., "name" = .)
anti_join(twitterNames, harryNames)
twitterNames
anti_join(twitterNames, harryNames)
twitterNames
harryNames
twitterNames %>% anti_join(harryNames)
harryNames %>% anti_join(twitterNames)
twitterNames %>% inner_join(harryNames)
twitterNames %>% inner_join(harryNames) %>% ncol()
twitterNames %>% inner_join(harryNames) %>% ncrow()
twitterNames %>% inner_join(harryNames) %>% nrow()
harryNames %>% inner_join(twitterNames) %>% nrow()
twitterNames %>% unique()
twitterNames %>% unique() %>% nrow9)
twitterNames %>% unique() %>% nrow()
harryNames %>% unique() %>% nrow()
colnames(harrypotter)
colnames(harrypotter) %>% nrow()
colnames(harrypotter) %>% length()
View(harrypotter)
harryNames %>% filter(name %in% twitterNames$name)
harryNames %>% filter(!name %in% twitterNames$name)
twitterNames %>% filter(!name %in% harryNames$name)
harryNames %>% filter(name %in% twitterNames$name)
harryNames %>% filter(name %in% twitterNames$name) %>% nrow9)
harryNames %>% str_detect(twitterNames$name)
harryNames$name %in% twitterNames$name
harryNames %>% select(name) %>% filter(name %in% twitterNames$name)
harryNames %>% select(name) %>% filter(!name %in% twitterNames$name)
twitterNames %>% select(name) %>% filter(!name %in% harryNames$name)
twitterNames <- df %>% colnames() %>% as.data.frame() %>% rename(., "name" = .)
harryNames <- harrypotter %>% colnames() %>% as.data.frame() %>% rename(., "name" = .)
twitterNames %>% select(name) %>% filter(!name %in% harryNames$name)
twitterNames %>% select(name) %>% filter(!name %in% harryNames$name)
twitterNames %>% select(name) %>% filter(!name %in% harryNames$name) %>% arrange()
harryNames %>% select(name) %>% filter(name %in% twitterNames$name)
harryNames %>% select(name) %>% filter(!name %in% twitterNames$name)
twitterNames %>% select(name) %>% filter(!name %in% harryNames$name)
bowFeatures <- tweetData %>%
unnest_tokens(word, "text") %>%
right_join(bow, by = c("word" = "bow")) %>%
count(word, word) %>%
mutate(n = n-1) %>%
spread(word, n)
bow <- read.csv("bowlist.csv", header = TRUE,stringsAsFactors = FALSE)
bigram <- read.csv("bigramlist.csv", header = TRUE,stringsAsFactors = FALSE)
trigram <- read.csv("trigramlist.csv", header = TRUE,stringsAsFactors = FALSE)
token <- readRDS("twitter_token.rds")
bowFeatures <- tweetData %>%
unnest_tokens(word, "text") %>%
right_join(bow, by = c("word" = "bow")) %>%
count(word, word) %>%
mutate(n = n-1) %>%
spread(word, n)
df <- cbind(bowFeatures, bigramFeatures, trigramFeatures, sentiments, emotionFeatures)
twitterNames %>% select(name) %>% filter(!name %in% harryNames$name)
View(bow)
bowFeatures <- tweetData %>%
unnest_tokens(word, "text") %>%
right_join(bow, by = c("word" = "bow")) %>%
count(word, word) %>%
mutate(n = n-1) %>%
spread(word, n)
df <- cbind(bowFeatures, bigramFeatures, trigramFeatures, sentiments, emotionFeatures)
twitterNames <- df %>% colnames() %>% as.data.frame() %>% rename(., "name" = .)
harryNames <- harrypotter %>% colnames() %>% as.data.frame() %>% rename(., "name" = .)
twitterNames %>% select(name) %>% filter(!name %in% harryNames$name)
LogisticRegressionModel <- readRDS("LogisticRegressionModel.rds")
